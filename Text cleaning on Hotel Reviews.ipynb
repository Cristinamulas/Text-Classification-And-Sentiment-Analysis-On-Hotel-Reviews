{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.tokens import Token\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data preprocesing revies\\n1--> remove puntuation\\n2--> lower\\n3--> remove $%^&\\n4__> remove stop wrods like hotel , hotels . nyc, \\n\\n\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"data preprocesing revies\n",
    "1--> remove puntuation\n",
    "2--> lower\n",
    "3--> remove $%^&\n",
    "4__> remove stop wrods like hotel , hotels . nyc, \n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only upload two features\n",
    "df_1 = pd.read_csv('five_hotels.csv', usecols = ['reviews', 'review_rating'])\n",
    "df_2 = pd.read_csv('last_hotels.csv', usecols = ['reviews', 'review_rating'])\n",
    "df = pd.concat([df_1, df_2])\n",
    "# reseting index\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>review_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Let me start off by saying that I understand t...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We had yet another wonderful visit at this hot...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It was one of the best hotels I have ever stay...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This hotel is just fantastic.  The location is...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazing park views from this hotel : ) Nicole ...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  review_rating\n",
       "0  Let me start off by saying that I understand t...             10\n",
       "1  We had yet another wonderful visit at this hot...             50\n",
       "2  It was one of the best hotels I have ever stay...             50\n",
       "3  This hotel is just fantastic.  The location is...             50\n",
       "4  Amazing park views from this hotel : ) Nicole ...             50"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First convert to lower case then removed Punctuations, Numbers, Special Characters and finally remove duplicated spaces \n",
    "# return a list of characters\n",
    "\n",
    "df['ti'] = df['reviews'].str.replace(\"[^a-zA-Z]\", \" \").str.replace(\"\\s+\", \" \").str.lower()\n",
    "#\" \".join(df['ti'].str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['tete'] = df['reviews'].str.lower().str.replace(\"[^a-z#]\", \" \").str.translate(str.maketrans(' ', ' ', '\\n\\t\\r'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we had yet another wonderful visit at this hotel this time with a full park view thank you for the upgrade we love staying here when ever we come to nyc it is a perfect location for us near subways and the park everything we want to do is within walking distance want to go to a play we walk the museums we walk always clean and with helpful people on staff we always enjoy our stay here '"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ti'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>ti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Let me start off by saying that I understand t...</td>\n",
       "      <td>10</td>\n",
       "      <td>let me start off by saying that i understand t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We had yet another wonderful visit at this hot...</td>\n",
       "      <td>50</td>\n",
       "      <td>we had yet another wonderful visit at this hot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It was one of the best hotels I have ever stay...</td>\n",
       "      <td>50</td>\n",
       "      <td>it was one of the best hotels i have ever stay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This hotel is just fantastic.  The location is...</td>\n",
       "      <td>50</td>\n",
       "      <td>this hotel is just fantastic the location is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazing park views from this hotel : ) Nicole ...</td>\n",
       "      <td>50</td>\n",
       "      <td>amazing park views from this hotel   nicole an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  review_rating  \\\n",
       "0  Let me start off by saying that I understand t...             10   \n",
       "1  We had yet another wonderful visit at this hot...             50   \n",
       "2  It was one of the best hotels I have ever stay...             50   \n",
       "3  This hotel is just fantastic.  The location is...             50   \n",
       "4  Amazing park views from this hotel : ) Nicole ...             50   \n",
       "\n",
       "                                                  ti  \n",
       "0  let me start off by saying that i understand t...  \n",
       "1  we had yet another wonderful visit at this hot...  \n",
       "2  it was one of the best hotels i have ever stay...  \n",
       "3  this hotel is just fantastic the location is s...  \n",
       "4  amazing park views from this hotel   nicole an...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize, Remove Stop Words and LemmatizationÂ¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "added_stopwords = ['thee', 'thing', 'thy', 'ye', 'thou', 'hath']\n",
    "nlp.Defaults.stop_words |= {'thee', 'thing', 'thy', 'ye', 'thou', 'hath'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it takes time becuase it returns meninfull words\n",
    "def remove_stop(doc_tokens):\n",
    "    \"\"\"removes stop words and returns list of all nonstop words that are lemmatized\"\"\"\n",
    "    return [token.lemma_ for token in doc_tokens if not token.is_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Reviews_tokenize'] = df['ti'].apply(lambda x: remove_stop(nlp(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note no tengo claro si despues de preprocesing tengo que return in str o unas lista de str!!!\n",
    "# jueves creo qie no lo voy a usar porque necesito una lista de workds\n",
    "df['Reviews_tokenize_join'] = df['Reviews_tokenize'].apply(lambda x: ' '.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>ti</th>\n",
       "      <th>l</th>\n",
       "      <th>Reviews_tokenize</th>\n",
       "      <th>Reviews_tokenize_join</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Let me start off by saying that I understand t...</td>\n",
       "      <td>10</td>\n",
       "      <td>let me start off by saying that i understand t...</td>\n",
       "      <td>start saying that understand that this hard ti...</td>\n",
       "      <td>[let, start, say, understand, hard, time, city...</td>\n",
       "      <td>let start say understand hard time city countr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We had yet another wonderful visit at this hot...</td>\n",
       "      <td>50</td>\n",
       "      <td>we had yet another wonderful visit at this hot...</td>\n",
       "      <td>another wonderful visit this hotel this time w...</td>\n",
       "      <td>[wonderful, visit, hotel, time, park, view, th...</td>\n",
       "      <td>wonderful visit hotel time park view thank upg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It was one of the best hotels I have ever stay...</td>\n",
       "      <td>50</td>\n",
       "      <td>it was one of the best hotels i have ever stay...</td>\n",
       "      <td>best hotels have ever stayed. Absolutely worth...</td>\n",
       "      <td>[good, hotel, stay, absolutely, worth, money, ...</td>\n",
       "      <td>good hotel stay absolutely worth money view ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This hotel is just fantastic.  The location is...</td>\n",
       "      <td>50</td>\n",
       "      <td>this hotel is just fantastic the location is s...</td>\n",
       "      <td>This hotel just fantastic. location spot being...</td>\n",
       "      <td>[hotel, fantastic, location, spot, step, centr...</td>\n",
       "      <td>hotel fantastic location spot step central par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazing park views from this hotel : ) Nicole ...</td>\n",
       "      <td>50</td>\n",
       "      <td>amazing park views from this hotel nicole and ...</td>\n",
       "      <td>Amazing park views from this hotel Nicole staf...</td>\n",
       "      <td>[amazing, park, view, hotel, nicole, staff, pr...</td>\n",
       "      <td>amazing park view hotel nicole staff professio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  review_rating  \\\n",
       "0  Let me start off by saying that I understand t...             10   \n",
       "1  We had yet another wonderful visit at this hot...             50   \n",
       "2  It was one of the best hotels I have ever stay...             50   \n",
       "3  This hotel is just fantastic.  The location is...             50   \n",
       "4  Amazing park views from this hotel : ) Nicole ...             50   \n",
       "\n",
       "                                                  ti  \\\n",
       "0  let me start off by saying that i understand t...   \n",
       "1  we had yet another wonderful visit at this hot...   \n",
       "2  it was one of the best hotels i have ever stay...   \n",
       "3  this hotel is just fantastic the location is s...   \n",
       "4  amazing park views from this hotel nicole and ...   \n",
       "\n",
       "                                                   l  \\\n",
       "0  start saying that understand that this hard ti...   \n",
       "1  another wonderful visit this hotel this time w...   \n",
       "2  best hotels have ever stayed. Absolutely worth...   \n",
       "3  This hotel just fantastic. location spot being...   \n",
       "4  Amazing park views from this hotel Nicole staf...   \n",
       "\n",
       "                                    Reviews_tokenize  \\\n",
       "0  [let, start, say, understand, hard, time, city...   \n",
       "1  [wonderful, visit, hotel, time, park, view, th...   \n",
       "2  [good, hotel, stay, absolutely, worth, money, ...   \n",
       "3  [hotel, fantastic, location, spot, step, centr...   \n",
       "4  [amazing, park, view, hotel, nicole, staff, pr...   \n",
       "\n",
       "                               Reviews_tokenize_join  \n",
       "0  let start say understand hard time city countr...  \n",
       "1  wonderful visit hotel time park view thank upg...  \n",
       "2  good hotel stay absolutely worth money view ce...  \n",
       "3  hotel fantastic location spot step central par...  \n",
       "4  amazing park view hotel nicole staff professio...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['let',\n",
       " 'start',\n",
       " 'say',\n",
       " 'understand',\n",
       " 'hard',\n",
       " 'time',\n",
       " 'city',\n",
       " 'country',\n",
       " 'entire',\n",
       " 'world',\n",
       " 'healthcare',\n",
       " 'provider',\n",
       " 'epidemiologist',\n",
       " 'people',\n",
       " 'say',\n",
       " 'hotel',\n",
       " 've',\n",
       " 'bother',\n",
       " 'stay',\n",
       " 'open',\n",
       " 'decide',\n",
       " 'stay',\n",
       " 'birthday',\n",
       " 'get',\n",
       " 'food',\n",
       " 'nice',\n",
       " 'restaurant',\n",
       " 'book',\n",
       " 'room',\n",
       " 'ability',\n",
       " 'eat',\n",
       " 'socially',\n",
       " 'distance',\n",
       " 'enter',\n",
       " 's',\n",
       " 'home',\n",
       " 'desk',\n",
       " 'guy',\n",
       " 's',\n",
       " 'attitude',\n",
       " 'cold',\n",
       " 'uninviting',\n",
       " 'wine',\n",
       " 'glass',\n",
       " 'provide',\n",
       " 'drinking',\n",
       " 'glass',\n",
       " 'one',\n",
       " 'sit',\n",
       " 'bathroom',\n",
       " 'ice',\n",
       " 'bucket',\n",
       " 'ability',\n",
       " 'coffee',\n",
       " 'response',\n",
       " 'hotel',\n",
       " 'essentially',\n",
       " 'close',\n",
       " 'fine',\n",
       " 'lot',\n",
       " 'hotel',\n",
       " 'actually',\n",
       " 'closed',\n",
       " 'don',\n",
       " 't',\n",
       " 'point',\n",
       " 'stay',\n",
       " 'open',\n",
       " 'charge',\n",
       " 'people',\n",
       " 'money',\n",
       " 'guise',\n",
       " 'open',\n",
       " 'have',\n",
       " 'actually',\n",
       " 'open',\n",
       " 'stay',\n",
       " 'hotel',\n",
       " 'pandemic',\n",
       " 'maintain',\n",
       " 'social',\n",
       " 'distancing',\n",
       " 'stay',\n",
       " 'hotel',\n",
       " 'mother',\n",
       " 'bring',\n",
       " 'grocery',\n",
       " 'win',\n",
       " 't',\n",
       " 'enter',\n",
       " 'home',\n",
       " 'risk',\n",
       " 'hotel',\n",
       " 'go',\n",
       " 'way',\n",
       " 'try',\n",
       " 'guest',\n",
       " 'comfortable',\n",
       " 'despite',\n",
       " 'limitation',\n",
       " 'unfortunately',\n",
       " 'clearly',\n",
       " 'case',\n",
       " 'hotel',\n",
       " 'think',\n",
       " 'figure',\n",
       " 'stay',\n",
       " 'open',\n",
       " 'collect',\n",
       " 'money',\n",
       " 'actually',\n",
       " 'behave',\n",
       " 'like',\n",
       " 'hotel',\n",
       " 'willing',\n",
       " 'provide',\n",
       " 'bed',\n",
       " 'sleep',\n",
       " 'desperate',\n",
       " 'need',\n",
       " 'location',\n",
       " 'convenient',\n",
       " 'guess',\n",
       " 'stay',\n",
       " 'lot',\n",
       " 'hotel',\n",
       " 'close',\n",
       " 'city',\n",
       " 'open']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Reviews_tokenize'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter(st_):\n",
    "    dic = {}\n",
    "    all_words = ' '.join([text for text in st_])\n",
    "    all_words = all_words.split()\n",
    "    for i in all_words:\n",
    "        if i not in dic:\n",
    "            dic[i] = 1\n",
    "        else:\n",
    "            dic[i] +=1\n",
    "    return dic\n",
    "#     return sorted(dic, key=lambda x: x[0]) \n",
    "#     return {k: v for k, v in sorted(dic.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-158-e4b98ccd2c96>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-158-e4b98ccd2c96>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    count_dict = {k:word , v:count  for k , v in counter(df['Reviews_tokenize_join']).items()}\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "count_dict = {k:word , v:count  for k , v in counter(df['Reviews_tokenize_join']).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']}\n",
    "pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = df['Reviews_tokenize'].apply(lambda x : counter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'itmes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-ab4f5ba36947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitmes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'itmes'"
     ]
    }
   ],
   "source": [
    "for k, v in dict_.itmes():\n",
    "    print(k, v)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'let': 1, 'start': 1, 'say': 2, 'understand': 1, 'hard': 1, 'time': 1, 'city': 2, 'country': 1, 'entire': 1, 'world': 1, 'healthcare': 1, 'provider': 1, 'epidemiologist': 1, 'people': 2, 'hotel': 9, 've': 1, 'bother': 1, 'stay': 7, 'open': 6, 'decide': 1, 'birthday': 1, 'get': 1, 'food': 1, 'nice': 1, 'restaurant': 1, 'book': 1, 'room': 1, 'ability': 2, 'eat': 1, 'socially': 1, 'distance': 1, 'enter': 2, 's': 2, 'home': 2, 'desk': 1, 'guy': 1, 'attitude': 1, 'cold': 1, 'uninviting': 1, 'wine': 1, 'glass': 2, 'provide': 2, 'drinking': 1, 'one': 1, 'sit': 1, 'bathroom': 1, 'ice': 1, 'bucket': 1, 'coffee': 1, 'response': 1, 'essentially': 1, 'close': 2, 'fine': 1, 'lot': 2, 'actually': 3, 'closed': 1, 'don': 1, 't': 2, 'point': 1, 'charge': 1, 'money': 2, 'guise': 1, 'have': 1, 'pandemic': 1, 'maintain': 1, 'social': 1, 'distancing': 1, 'mother': 1, 'bring': 1, 'grocery': 1, 'win': 1, 'risk': 1, 'go': 1, 'way': 1, 'try': 1, 'guest': 1, 'comfortable': 1, 'despite': 1, 'limitation': 1, 'unfortunately': 1, 'clearly': 1, 'case': 1, 'think': 1, 'figure': 1, 'collect': 1, 'behave': 1, 'like': 1, 'willing': 1, 'bed': 1, 'sleep': 1, 'desperate': 1, 'need': 1, 'location': 1, 'convenient': 1, 'guess': 1}\n"
     ]
    }
   ],
   "source": [
    "dict_ = {}\n",
    "all_words = ' '.join([text for text in l])\n",
    "all_words = all_words.split()\n",
    "for i in all_words:\n",
    "    if i not in dict_:\n",
    "        dict_[i] = 1\n",
    "    else:\n",
    "        dict_[i] += 1\n",
    "print(dict_)\n",
    "#     words_df = pd.DataFrame({'word': list(dict_.keys()) , 'count':list(dict_.values())})\n",
    "#     df_sort = words_df.nlargest(columns = 'count' , n = 20)\n",
    "#     print(df_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = df['Reviews_tokenize'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = ' '.join([text for text in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l',\n",
       " 'e',\n",
       " 't',\n",
       " 's',\n",
       " 't',\n",
       " 'a',\n",
       " 'r',\n",
       " 't',\n",
       " 's',\n",
       " 'a',\n",
       " 'y',\n",
       " 'u',\n",
       " 'n',\n",
       " 'd',\n",
       " 'e',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " 'h',\n",
       " 'a',\n",
       " 'r',\n",
       " 'd',\n",
       " 't',\n",
       " 'i',\n",
       " 'm',\n",
       " 'e',\n",
       " 'c',\n",
       " 'i',\n",
       " 't',\n",
       " 'y',\n",
       " 'c',\n",
       " 'o',\n",
       " 'u',\n",
       " 'n',\n",
       " 't',\n",
       " 'r',\n",
       " 'y',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 'i',\n",
       " 'r',\n",
       " 'e',\n",
       " 'w',\n",
       " 'o',\n",
       " 'r',\n",
       " 'l',\n",
       " 'd',\n",
       " 'h',\n",
       " 'e',\n",
       " 'a',\n",
       " 'l',\n",
       " 't',\n",
       " 'h',\n",
       " 'c',\n",
       " 'a',\n",
       " 'r',\n",
       " 'e',\n",
       " 'p',\n",
       " 'r',\n",
       " 'o',\n",
       " 'v',\n",
       " 'i',\n",
       " 'd',\n",
       " 'e',\n",
       " 'r',\n",
       " 'e',\n",
       " 'p',\n",
       " 'i',\n",
       " 'd',\n",
       " 'e',\n",
       " 'm',\n",
       " 'i',\n",
       " 'o',\n",
       " 'l',\n",
       " 'o',\n",
       " 'g',\n",
       " 'i',\n",
       " 's',\n",
       " 't',\n",
       " 'p',\n",
       " 'e',\n",
       " 'o',\n",
       " 'p',\n",
       " 'l',\n",
       " 'e',\n",
       " 's',\n",
       " 'a',\n",
       " 'y',\n",
       " 'h',\n",
       " 'o',\n",
       " 't',\n",
       " 'e',\n",
       " 'l',\n",
       " 'v',\n",
       " 'e',\n",
       " 'b',\n",
       " 'o',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'a',\n",
       " 'y',\n",
       " 'o',\n",
       " 'p',\n",
       " 'e',\n",
       " 'n',\n",
       " 'd',\n",
       " 'e',\n",
       " 'c',\n",
       " 'i',\n",
       " 'd',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " 'a',\n",
       " 'y',\n",
       " 'b',\n",
       " 'i',\n",
       " 'r',\n",
       " 't',\n",
       " 'h',\n",
       " 'd',\n",
       " 'a',\n",
       " 'y',\n",
       " 'g',\n",
       " 'e',\n",
       " 't',\n",
       " 'f',\n",
       " 'o',\n",
       " 'o',\n",
       " 'd',\n",
       " 'n',\n",
       " 'i',\n",
       " 'c',\n",
       " 'e',\n",
       " 'r',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " 'a',\n",
       " 'u',\n",
       " 'r',\n",
       " 'a',\n",
       " 'n',\n",
       " 't',\n",
       " 'b',\n",
       " 'o',\n",
       " 'o',\n",
       " 'k',\n",
       " 'r',\n",
       " 'o',\n",
       " 'o',\n",
       " 'm',\n",
       " 'a',\n",
       " 'b',\n",
       " 'i',\n",
       " 'l',\n",
       " 'i',\n",
       " 't',\n",
       " 'y',\n",
       " 'e',\n",
       " 'a',\n",
       " 't',\n",
       " 's',\n",
       " 'o',\n",
       " 'c',\n",
       " 'i',\n",
       " 'a',\n",
       " 'l',\n",
       " 'l',\n",
       " 'y',\n",
       " 'd',\n",
       " 'i',\n",
       " 's',\n",
       " 't',\n",
       " 'a',\n",
       " 'n',\n",
       " 'c',\n",
       " 'e',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 'e',\n",
       " 'r',\n",
       " 's',\n",
       " 'h',\n",
       " 'o',\n",
       " 'm',\n",
       " 'e',\n",
       " 'd',\n",
       " 'e',\n",
       " 's',\n",
       " 'k',\n",
       " 'g',\n",
       " 'u',\n",
       " 'y',\n",
       " 's',\n",
       " 'a',\n",
       " 't',\n",
       " 't',\n",
       " 'i',\n",
       " 't',\n",
       " 'u',\n",
       " 'd',\n",
       " 'e',\n",
       " 'c',\n",
       " 'o',\n",
       " 'l',\n",
       " 'd',\n",
       " 'u',\n",
       " 'n',\n",
       " 'i',\n",
       " 'n',\n",
       " 'v',\n",
       " 'i',\n",
       " 't',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " 'w',\n",
       " 'i',\n",
       " 'n',\n",
       " 'e',\n",
       " 'g',\n",
       " 'l',\n",
       " 'a',\n",
       " 's',\n",
       " 's',\n",
       " 'p',\n",
       " 'r',\n",
       " 'o',\n",
       " 'v',\n",
       " 'i',\n",
       " 'd',\n",
       " 'e',\n",
       " 'd',\n",
       " 'r',\n",
       " 'i',\n",
       " 'n',\n",
       " 'k',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " 'g',\n",
       " 'l',\n",
       " 'a',\n",
       " 's',\n",
       " 's',\n",
       " 'o',\n",
       " 'n',\n",
       " 'e',\n",
       " 's',\n",
       " 'i',\n",
       " 't',\n",
       " 'b',\n",
       " 'a',\n",
       " 't',\n",
       " 'h',\n",
       " 'r',\n",
       " 'o',\n",
       " 'o',\n",
       " 'm',\n",
       " 'i',\n",
       " 'c',\n",
       " 'e',\n",
       " 'b',\n",
       " 'u',\n",
       " 'c',\n",
       " 'k',\n",
       " 'e',\n",
       " 't',\n",
       " 'a',\n",
       " 'b',\n",
       " 'i',\n",
       " 'l',\n",
       " 'i',\n",
       " 't',\n",
       " 'y',\n",
       " 'c',\n",
       " 'o',\n",
       " 'f',\n",
       " 'f',\n",
       " 'e',\n",
       " 'e',\n",
       " 'r',\n",
       " 'e',\n",
       " 's',\n",
       " 'p',\n",
       " 'o',\n",
       " 'n',\n",
       " 's',\n",
       " 'e',\n",
       " 'h',\n",
       " 'o',\n",
       " 't',\n",
       " 'e',\n",
       " 'l',\n",
       " 'e',\n",
       " 's',\n",
       " 's',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 'i',\n",
       " 'a',\n",
       " 'l',\n",
       " 'l',\n",
       " 'y',\n",
       " 'c',\n",
       " 'l',\n",
       " 'o',\n",
       " 's',\n",
       " 'e',\n",
       " 'f',\n",
       " 'i',\n",
       " 'n',\n",
       " 'e',\n",
       " 'l',\n",
       " 'o',\n",
       " 't',\n",
       " 'h',\n",
       " 'o',\n",
       " 't',\n",
       " 'e',\n",
       " 'l',\n",
       " 'a',\n",
       " 'c',\n",
       " 't',\n",
       " 'u',\n",
       " 'a',\n",
       " 'l',\n",
       " 'l',\n",
       " 'y',\n",
       " 'c',\n",
       " 'l',\n",
       " 'o',\n",
       " 's',\n",
       " 'e',\n",
       " 'd',\n",
       " 'd',\n",
       " 'o',\n",
       " 'n',\n",
       " 't',\n",
       " 'p',\n",
       " 'o',\n",
       " 'i',\n",
       " 'n',\n",
       " 't',\n",
       " 's',\n",
       " 't',\n",
       " 'a',\n",
       " 'y',\n",
       " 'o',\n",
       " 'p',\n",
       " 'e',\n",
       " 'n',\n",
       " 'c',\n",
       " 'h',\n",
       " 'a',\n",
       " 'r',\n",
       " 'g',\n",
       " 'e',\n",
       " 'p',\n",
       " 'e',\n",
       " 'o',\n",
       " 'p',\n",
       " 'l',\n",
       " 'e',\n",
       " 'm',\n",
       " 'o',\n",
       " 'n',\n",
       " 'e',\n",
       " 'y',\n",
       " 'g',\n",
       " 'u',\n",
       " 'i',\n",
       " 's',\n",
       " 'e',\n",
       " 'o',\n",
       " 'p',\n",
       " 'e',\n",
       " 'n',\n",
       " 'h',\n",
       " 'a',\n",
       " 'v',\n",
       " 'e',\n",
       " 'a',\n",
       " 'c',\n",
       " 't',\n",
       " 'u',\n",
       " 'a',\n",
       " 'l',\n",
       " 'l',\n",
       " 'y',\n",
       " 'o',\n",
       " 'p',\n",
       " 'e',\n",
       " 'n',\n",
       " 's',\n",
       " 't',\n",
       " 'a',\n",
       " 'y',\n",
       " 'h',\n",
       " 'o',\n",
       " 't',\n",
       " 'e',\n",
       " 'l',\n",
       " 'p',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " 'e',\n",
       " 'm',\n",
       " 'i',\n",
       " 'c',\n",
       " 'm',\n",
       " 'a',\n",
       " 'i',\n",
       " 'n',\n",
       " 't',\n",
       " 'a',\n",
       " 'i',\n",
       " 'n',\n",
       " 's',\n",
       " 'o',\n",
       " 'c',\n",
       " 'i',\n",
       " 'a',\n",
       " 'l',\n",
       " 'd',\n",
       " 'i',\n",
       " 's',\n",
       " 't',\n",
       " 'a',\n",
       " 'n',\n",
       " 'c',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " 's',\n",
       " 't',\n",
       " 'a',\n",
       " 'y',\n",
       " 'h',\n",
       " 'o',\n",
       " 't',\n",
       " 'e',\n",
       " 'l',\n",
       " 'm',\n",
       " 'o',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'r',\n",
       " 'b',\n",
       " 'r',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " 'g',\n",
       " 'r',\n",
       " 'o',\n",
       " 'c',\n",
       " 'e',\n",
       " 'r',\n",
       " 'y',\n",
       " 'w',\n",
       " 'i',\n",
       " 'n',\n",
       " 't',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 'e',\n",
       " 'r',\n",
       " 'h',\n",
       " 'o',\n",
       " 'm',\n",
       " 'e',\n",
       " 'r',\n",
       " 'i',\n",
       " 's',\n",
       " 'k',\n",
       " 'h',\n",
       " 'o',\n",
       " 't',\n",
       " 'e',\n",
       " 'l',\n",
       " 'g',\n",
       " 'o',\n",
       " 'w',\n",
       " 'a',\n",
       " 'y',\n",
       " 't',\n",
       " 'r',\n",
       " 'y',\n",
       " 'g',\n",
       " 'u',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " 'c',\n",
       " 'o',\n",
       " 'm',\n",
       " 'f',\n",
       " 'o',\n",
       " 'r',\n",
       " 't',\n",
       " 'a',\n",
       " 'b',\n",
       " 'l',\n",
       " 'e',\n",
       " 'd',\n",
       " 'e',\n",
       " 's',\n",
       " 'p',\n",
       " 'i',\n",
       " 't',\n",
       " 'e',\n",
       " 'l',\n",
       " 'i',\n",
       " 'm',\n",
       " 'i',\n",
       " 't',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'o',\n",
       " 'n',\n",
       " 'u',\n",
       " 'n',\n",
       " 'f',\n",
       " 'o',\n",
       " 'r',\n",
       " 't',\n",
       " 'u',\n",
       " 'n',\n",
       " 'a',\n",
       " 't',\n",
       " 'e',\n",
       " 'l',\n",
       " 'y',\n",
       " 'c',\n",
       " 'l',\n",
       " 'e',\n",
       " 'a',\n",
       " 'r',\n",
       " 'l',\n",
       " 'y',\n",
       " 'c',\n",
       " 'a',\n",
       " 's',\n",
       " 'e',\n",
       " 'h',\n",
       " 'o',\n",
       " 't',\n",
       " 'e',\n",
       " 'l',\n",
       " 't',\n",
       " 'h',\n",
       " 'i',\n",
       " 'n',\n",
       " 'k',\n",
       " 'f',\n",
       " 'i',\n",
       " 'g',\n",
       " 'u',\n",
       " 'r',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " 'a',\n",
       " 'y',\n",
       " 'o',\n",
       " 'p',\n",
       " 'e',\n",
       " 'n',\n",
       " 'c',\n",
       " 'o',\n",
       " 'l',\n",
       " 'l',\n",
       " 'e',\n",
       " 'c',\n",
       " 't',\n",
       " 'm',\n",
       " 'o',\n",
       " 'n',\n",
       " 'e',\n",
       " 'y',\n",
       " 'a',\n",
       " 'c',\n",
       " 't',\n",
       " 'u',\n",
       " 'a',\n",
       " 'l',\n",
       " 'l',\n",
       " 'y',\n",
       " 'b',\n",
       " 'e',\n",
       " 'h',\n",
       " 'a',\n",
       " 'v',\n",
       " 'e',\n",
       " 'l',\n",
       " 'i',\n",
       " 'k',\n",
       " 'e',\n",
       " 'h',\n",
       " 'o',\n",
       " 't',\n",
       " 'e',\n",
       " 'l',\n",
       " 'w',\n",
       " 'i',\n",
       " 'l',\n",
       " 'l',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " 'p',\n",
       " 'r',\n",
       " 'o',\n",
       " 'v',\n",
       " 'i',\n",
       " 'd',\n",
       " 'e',\n",
       " 'b',\n",
       " 'e',\n",
       " 'd',\n",
       " 's',\n",
       " 'l',\n",
       " 'e',\n",
       " 'e',\n",
       " 'p',\n",
       " 'd',\n",
       " 'e',\n",
       " 's',\n",
       " 'p',\n",
       " 'e',\n",
       " 'r',\n",
       " 'a',\n",
       " 't',\n",
       " 'e',\n",
       " 'n',\n",
       " 'e',\n",
       " 'e',\n",
       " 'd',\n",
       " 'l',\n",
       " 'o',\n",
       " 'c',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'o',\n",
       " 'n',\n",
       " 'c',\n",
       " 'o',\n",
       " 'n',\n",
       " 'v',\n",
       " 'e',\n",
       " 'n',\n",
       " 'i',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 'g',\n",
       " 'u',\n",
       " 'e',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 't',\n",
       " 'a',\n",
       " 'y',\n",
       " 'l',\n",
       " 'o',\n",
       " 't',\n",
       " 'h',\n",
       " 'o',\n",
       " 't',\n",
       " 'e',\n",
       " 'l',\n",
       " 'c',\n",
       " 'l',\n",
       " 'o',\n",
       " 's',\n",
       " 'e',\n",
       " 'c',\n",
       " 'i',\n",
       " 't',\n",
       " 'y',\n",
       " 'o',\n",
       " 'p',\n",
       " 'e',\n",
       " 'n']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        {'let': 1, 'start': 1, 'say': 2, 'understand':...\n",
       "1        {'wonderful': 1, 'visit': 1, 'hotel': 1, 'time...\n",
       "2        {'good': 2, 'hotel': 1, 'stay': 1, 'absolutely...\n",
       "3        {'hotel': 3, 'fantastic': 2, 'location': 1, 's...\n",
       "4        {'amazing': 1, 'park': 2, 'view': 1, 'hotel': ...\n",
       "                               ...                        \n",
       "25045    {'th': 1, 'stay': 1, 'park': 1, 'central': 1, ...\n",
       "25046    {'stay': 1, 'business': 1, 'trip': 2, 'extend'...\n",
       "25047    {'love': 1, 'stay': 2, 'park': 1, 'central': 1...\n",
       "25048    {'great': 1, 'location': 1, 'couple': 1, 'bloc...\n",
       "25049    {'pleasantly': 1, 'surprised': 1, 'spacious': ...\n",
       "Name: dict, Length: 25050, dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        {'l': 48, 'e': 93, 't': 70, ' ': 128, 's': 41,...\n",
       "1        {'w': 8, 'o': 8, 'n': 10, 'd': 3, 'e': 17, 'r'...\n",
       "2        {'g': 3, 'o': 13, 'd': 4, ' ': 18, 'h': 2, 't'...\n",
       "3        {'h': 8, 'o': 25, 't': 29, 'e': 30, 'l': 16, '...\n",
       "4        {'a': 13, 'm': 5, 'z': 1, 'i': 7, 'n': 7, 'g':...\n",
       "                               ...                        \n",
       "25045    {'t': 21, 'h': 3, ' ': 46, 's': 14, 'a': 24, '...\n",
       "25046    {'s': 22, 't': 32, 'a': 26, 'y': 9, ' ': 62, '...\n",
       "25047    {'l': 12, 'o': 9, 'v': 1, 'e': 13, ' ': 18, 's...\n",
       "25048    {'g': 3, 'r': 16, 'e': 31, 'a': 23, 't': 20, '...\n",
       "25049    {'p': 6, 'l': 15, 'e': 27, 'a': 19, 's': 8, 'n...\n",
       "Name: Reviews_tokenize_join, Length: 25050, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Reviews_tokenize_join'].apply(lambda x : counter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'let': 1,\n",
       " 'start': 1,\n",
       " 'say': 2,\n",
       " 'understand': 1,\n",
       " 'hard': 1,\n",
       " 'time': 1,\n",
       " 'city': 2,\n",
       " 'country': 1,\n",
       " 'entire': 1,\n",
       " 'world': 1,\n",
       " 'healthcare': 1,\n",
       " 'provider': 1,\n",
       " 'epidemiologist': 1,\n",
       " 'people': 2,\n",
       " 'hotel': 9,\n",
       " 've': 1,\n",
       " 'bother': 1,\n",
       " 'stay': 7,\n",
       " 'open': 6,\n",
       " 'decide': 1,\n",
       " 'birthday': 1,\n",
       " 'get': 1,\n",
       " 'food': 1,\n",
       " 'nice': 1,\n",
       " 'restaurant': 1,\n",
       " 'book': 1,\n",
       " 'room': 1,\n",
       " 'ability': 2,\n",
       " 'eat': 1,\n",
       " 'socially': 1,\n",
       " 'distance': 1,\n",
       " 'enter': 2,\n",
       " 's': 2,\n",
       " 'home': 2,\n",
       " 'desk': 1,\n",
       " 'guy': 1,\n",
       " 'attitude': 1,\n",
       " 'cold': 1,\n",
       " 'uninviting': 1,\n",
       " 'wine': 1,\n",
       " 'glass': 2,\n",
       " 'provide': 2,\n",
       " 'drinking': 1,\n",
       " 'one': 1,\n",
       " 'sit': 1,\n",
       " 'bathroom': 1,\n",
       " 'ice': 1,\n",
       " 'bucket': 1,\n",
       " 'coffee': 1,\n",
       " 'response': 1,\n",
       " 'essentially': 1,\n",
       " 'close': 2,\n",
       " 'fine': 1,\n",
       " 'lot': 2,\n",
       " 'actually': 3,\n",
       " 'closed': 1,\n",
       " 'don': 1,\n",
       " 't': 2,\n",
       " 'point': 1,\n",
       " 'charge': 1,\n",
       " 'money': 2,\n",
       " 'guise': 1,\n",
       " 'have': 1,\n",
       " 'pandemic': 1,\n",
       " 'maintain': 1,\n",
       " 'social': 1,\n",
       " 'distancing': 1,\n",
       " 'mother': 1,\n",
       " 'bring': 1,\n",
       " 'grocery': 1,\n",
       " 'win': 1,\n",
       " 'risk': 1,\n",
       " 'go': 1,\n",
       " 'way': 1,\n",
       " 'try': 1,\n",
       " 'guest': 1,\n",
       " 'comfortable': 1,\n",
       " 'despite': 1,\n",
       " 'limitation': 1,\n",
       " 'unfortunately': 1,\n",
       " 'clearly': 1,\n",
       " 'case': 1,\n",
       " 'think': 1,\n",
       " 'figure': 1,\n",
       " 'collect': 1,\n",
       " 'behave': 1,\n",
       " 'like': 1,\n",
       " 'willing': 1,\n",
       " 'bed': 1,\n",
       " 'sleep': 1,\n",
       " 'desperate': 1,\n",
       " 'need': 1,\n",
       " 'location': 1,\n",
       " 'convenient': 1,\n",
       " 'guess': 1}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter(df['Reviews_tokenize'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('book standard room advance have year look forward visit opt upgrade suite suite lovely sit room bedroom massive bathroom sadly foot usable closet space jacket shirt blouse length move standard room good room apart closet area near basin bathroom pepper people s toothpaste yuk edge carpet vacuum long time fluff centimetre thick noise fan atrium loud early morning go customer service desk people tell hotel chance change didn t bother',\n",
       "  2),\n",
       " ('let start say understand hard time city country entire world healthcare provider epidemiologist people say hotel ve bother stay open decide stay birthday get food nice restaurant book room ability eat socially distance enter s home desk guy s attitude cold uninviting wine glass provide drinking glass one sit bathroom ice bucket ability coffee response hotel essentially close fine lot hotel actually closed don t point stay open charge people money guise open have actually open stay hotel pandemic maintain social distancing stay hotel mother bring grocery win t enter home risk hotel go way try guest comfortable despite limitation unfortunately clearly case hotel think figure stay open collect money actually behave like hotel willing provide bed sleep desperate need location convenient guess stay lot hotel close city open',\n",
       "  1),\n",
       " ('wonderful visit hotel time park view thank upgrade love stay come nyc perfect location near subway park want walk distance want play walk museum walk clean helpful people staff enjoy stay',\n",
       "  1),\n",
       " ('good hotel stay absolutely worth money view central park morning fascinate room ideal kind people time year good job',\n",
       "  1),\n",
       " ('hotel fantastic location spot step central park view room breathtake stay right covid limit course close room large beautiful bed comfortable overall accommodate ve stay time city hotel fully open bust bar restarurant downstairs great free extended happy hour w hor d oeuvre breakfast morning overall fantastic hotel',\n",
       "  1),\n",
       " ('amazing park view hotel nicole staff professional friendly accommodate stay highly recommend property location perfect central park stay safe',\n",
       "  1),\n",
       " ('staff parklane attentive usual prince team point desk alex head nabila amazing control doorman good attentive helpful america housekeeping good make sure m happy thank',\n",
       "  1),\n",
       " ('stay cruise end new york harbour visit new york hotel stop arrive meet exceed expectation room tastefully decorate nice size bed comfortable shower excellent water pressure location good close th ave central park concierge extremely helpful navigate city overall lovely stay hotel',\n",
       "  1),\n",
       " ('friendly staff nicole desk housekeeping manager vincent greet smile parking garage experience s tough time work nyc people well room clean location perfect view breathtake great value dollar wish city wasn t close advantage restaurant bar',\n",
       "  1),\n",
       " ('stay park lane hotel september good time moment airport arrive uber driver little bit selfish park opposite lane entrance luckily tim help carry bag help cross completely safe help give correct direction driver big smile thank tim good doorman meet',\n",
       "  1)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df['Reviews_tokenize_join']).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['l'] = df['reviews'].apply(lambda x: x.split())\n",
    "# lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [Let, me, start, off, by, saying, that, I, und...\n",
       "1        [We, had, yet, another, wonderful, visit, at, ...\n",
       "2        [It, was, one, of, the, best, hotels, I, have,...\n",
       "3        [This, hotel, is, just, fantastic., The, locat...\n",
       "4        [Amazing, park, views, from, this, hotel, :, )...\n",
       "                               ...                        \n",
       "25045    [It, was, my, 6th, stay, in, Park, Central,, I...\n",
       "25046    [I, stayed, here, for, a, business, trip,, but...\n",
       "25047    [Loved, our, stay, at, Park, Central., Central...\n",
       "25048    [Great, location,, a, couple, of, blocks, from...\n",
       "25049    [I, was, pleasantly, surprised, how, spacious,...\n",
       "Name: l, Length: 25050, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['l'] = df['l'].apply(lambda x: ' '.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Let me start off by saying that I understand t...\n",
       "1        We had yet another wonderful visit at this hot...\n",
       "2        It was one of the best hotels I have ever stay...\n",
       "3        This hotel is just fantastic. The location is ...\n",
       "4        Amazing park views from this hotel : ) Nicole ...\n",
       "                               ...                        \n",
       "25045    It was my 6th stay in Park Central, I always c...\n",
       "25046    I stayed here for a business trip, but extende...\n",
       "25047    Loved our stay at Park Central. Centrally loca...\n",
       "25048    Great location, a couple of blocks from Centra...\n",
       "25049    I was pleasantly surprised how spacious the ro...\n",
       "Name: l, Length: 25050, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['l'] = df['l'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        start saying that understand that this hard ti...\n",
       "1        another wonderful visit this hotel this time w...\n",
       "2        best hotels have ever stayed. Absolutely worth...\n",
       "3        This hotel just fantastic. location spot being...\n",
       "4        Amazing park views from this hotel Nicole staf...\n",
       "                               ...                        \n",
       "25045    stay Park Central, always choose mainly becaus...\n",
       "25046    stayed here business trip, extended trip coupl...\n",
       "25047    Loved stay Park Central. Centrally located, pr...\n",
       "25048    Great location, couple blocks from Central Par...\n",
       "25049    pleasantly surprised spacious rooms were. were...\n",
       "Name: l, Length: 25050, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
