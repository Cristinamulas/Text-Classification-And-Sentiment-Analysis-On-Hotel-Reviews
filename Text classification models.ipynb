{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains model training, data engineering and selection processes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "import timeit\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries form csv files into pandas df\n",
    "df = pd.read_csv('data_for_model.csv', usecols = ['review_rating' , 'Reviews_tokenize_join'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimazation memory by converting the review_rating to category\n",
    "df['target'] = df['review_rating'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a24dca358>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot\n",
    "df['review_rating'].plot.hist(bins=12, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.474172\n",
       "4    0.264351\n",
       "3    0.122715\n",
       "1    0.069501\n",
       "2    0.069261\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['target'].value_counts(normalize = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()\n",
    "# df['target'] = df['review_rating'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['target'] = df['review_rating'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25050 entries, 0 to 25049\n",
      "Data columns (total 3 columns):\n",
      " #   Column                 Non-Null Count  Dtype   \n",
      "---  ------                 --------------  -----   \n",
      " 0   review_rating          25050 non-null  int64   \n",
      " 1   Reviews_tokenize_join  25050 non-null  object  \n",
      " 2   target                 25050 non-null  category\n",
      "dtypes: category(1), int64(1), object(1)\n",
      "memory usage: 416.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_rating</th>\n",
       "      <th>Reviews_tokenize_join</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>start say understand hard time city country en...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>wonderful visit time park view thank upgrade l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>good hotel stay absolutely worth money view ce...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>fantastic location spot step central park view...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>amazing park view nicole staff professional fr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_rating                              Reviews_tokenize_join target\n",
       "0              1  start say understand hard time city country en...      1\n",
       "1              5  wonderful visit time park view thank upgrade l...      5\n",
       "2              5  good hotel stay absolutely worth money view ce...      5\n",
       "3              5  fantastic location spot step central park view...      5\n",
       "4              5  amazing park view nicole staff professional fr...      5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Engineering and Modelling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I am going to implement different classifiers to see which works best:\n",
    "\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Linear Support Vector Classification\n",
    "- Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf(model ,col1,col):\n",
    "    start = timeit.timeit()\n",
    "    \"\"\"It takes two columns and a classifier, split the data into traing and testing, vectorize it, remove irrlevant features using and implemnt a ca\n",
    "    classifier using a pipeline, return a dictionary with accuracy, precions and recall f_1 socre and running time\"\"\"\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[col1], df[col] , test_size=0.3, random_state = 42)\n",
    "\n",
    "    classification_model = Pipeline([('vect', TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\", sublinear_tf=True)),\n",
    "                         ('chi',  SelectKBest(chi2, k=10000)),\n",
    "                   ('clf', model)])\n",
    "\n",
    "    classification_model.fit(X_train, y_train)\n",
    "    \n",
    "    preds = classification_model.predict(X_test)\n",
    "    end = timeit.timeit()\n",
    "    final_time = start - end\n",
    "\n",
    "    list_names = ['Model','Accuracy_score','Recall_score','Precision_score','F1_score', 'Time']\n",
    "    score_list = []\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds,average=None, pos_label='Good')\n",
    "    precision = precision_score(y_test, preds,average=None, pos_label='Good')\n",
    "    f_1 = f1_score(y_test , preds,average=None, pos_label='Good')\n",
    "    final_time = start - end\n",
    "\n",
    "    score_list.extend([model,accuracy,recall,precision,f_1,final_time])\n",
    "    dictionary = dict(zip(list_names, score_list))\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_multi_class = clf(LogisticRegression() , df ,'Reviews_tokenize_join', 'target')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy_score': '60.0%',\n",
       " 'Recall_score': array([0.54420432, 0.03214286, 0.24946004, 0.39164619, 0.90588235]),\n",
       " 'Precision_score': array([0.57708333, 0.3       , 0.37806874, 0.47412255, 0.67414051]),\n",
       " 'F1_score': array([0.56016178, 0.05806452, 0.30058556, 0.42895587, 0.77301665]),\n",
       " 'Time': 0.0030548040000013543}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_multi_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_multi_class = clf(MultinomialNB(), df, 'Reviews_tokenize_join', 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy_score': '47.0%',\n",
       " 'Recall_score': array([0.01178782, 0.        , 0.00647948, 0.03587224, 0.99827834]),\n",
       " 'Precision_score': array([1.        , 0.        , 0.09230769, 0.11908646, 0.50929586]),\n",
       " 'F1_score': array([0.02330097, 0.        , 0.01210898, 0.05513595, 0.67448623]),\n",
       " 'Time': 0.0029241939999984368}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_multi_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_multi_class = clf(DecisionTreeClassifier(), df, 'Reviews_tokenize_join', 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy_score': '46.0%',\n",
       " 'Recall_score': array([0.32023576, 0.14464286, 0.21814255, 0.35872236, 0.66025825]),\n",
       " 'Precision_score': array([0.37385321, 0.21259843, 0.23461092, 0.3417603 , 0.62172386]),\n",
       " 'F1_score': array([0.34497354, 0.17215728, 0.22607722, 0.35003596, 0.64041191]),\n",
       " 'Time': 0.0028145990000041365}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_multi_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine with stochastic gradient descent (SGD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf(SGDClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with cross validation\n",
    "# clf(SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf(SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_multi_class = clf(LinearSVC(),df, 'Reviews_tokenize_join', 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy_score': '61.0%',\n",
       " 'Recall_score': array([0.58742633, 0.14464286, 0.35529158, 0.40884521, 0.87058824]),\n",
       " 'Precision_score': array([0.53680431, 0.34913793, 0.40220049, 0.49701314, 0.71658007]),\n",
       " 'F1_score': array([0.56097561, 0.20454545, 0.37729358, 0.44863845, 0.78611219]),\n",
       " 'Time': 0.003740172000000541}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_multi_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_multi_class = clf(RandomForestClassifier(),df, 'Reviews_tokenize_join', 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy_score': '53.0%',\n",
       " 'Recall_score': array([0.33791749, 0.07678571, 0.16954644, 0.35380835, 0.82266858]),\n",
       " 'Precision_score': array([0.4738292 , 0.29861111, 0.28390597, 0.38543897, 0.62502725]),\n",
       " 'F1_score': array([0.39449541, 0.12215909, 0.21230561, 0.36894696, 0.71035679]),\n",
       " 'Time': 0.00409076800000463}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_multi_class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "l= [lg_multi_class, dt_multi_class, nb_multi_class , svc_multi_class, rf_multi_class ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy_score</th>\n",
       "      <th>Recall_score</th>\n",
       "      <th>Precision_score</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regresion</th>\n",
       "      <td>59.61%</td>\n",
       "      <td>[0.5442043222003929, 0.03214285714285714, 0.24...</td>\n",
       "      <td>[0.5770833333333333, 0.3, 0.3780687397708674, ...</td>\n",
       "      <td>[0.5601617795753286, 0.058064516129032254, 0.3...</td>\n",
       "      <td>0.003744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>45.67%</td>\n",
       "      <td>[0.3280943025540275, 0.13214285714285715, 0.22...</td>\n",
       "      <td>[0.3856812933025404, 0.2138728323699422, 0.230...</td>\n",
       "      <td>[0.3545647558386412, 0.16335540838852097, 0.22...</td>\n",
       "      <td>0.003864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mutinomial NB</th>\n",
       "      <td>47.43%</td>\n",
       "      <td>[0.011787819253438114, 0.0, 0.0064794816414686...</td>\n",
       "      <td>[1.0, 0.0, 0.09230769230769231, 0.119086460032...</td>\n",
       "      <td>[0.023300970873786405, 0.0, 0.0121089808274470...</td>\n",
       "      <td>0.003270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Support Vector Classification</th>\n",
       "      <td>60.88%</td>\n",
       "      <td>[0.587426326129666, 0.14464285714285716, 0.355...</td>\n",
       "      <td>[0.5368043087971275, 0.34913793103448276, 0.40...</td>\n",
       "      <td>[0.5609756097560975, 0.20454545454545456, 0.37...</td>\n",
       "      <td>0.004425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>51.580000000000005%</td>\n",
       "      <td>[0.3005893909626719, 0.06964285714285715, 0.17...</td>\n",
       "      <td>[0.4751552795031056, 0.2932330827067669, 0.288...</td>\n",
       "      <td>[0.3682310469314079, 0.11255411255411255, 0.21...</td>\n",
       "      <td>0.002815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Accuracy_score  \\\n",
       "Model                                                       \n",
       "Logistic Regresion                                 59.61%   \n",
       "Decision Tree Classifier                           45.67%   \n",
       "Mutinomial NB                                      47.43%   \n",
       "Linear Support Vector Classification               60.88%   \n",
       "Random Forest Classifier              51.580000000000005%   \n",
       "\n",
       "                                                                           Recall_score  \\\n",
       "Model                                                                                     \n",
       "Logistic Regresion                    [0.5442043222003929, 0.03214285714285714, 0.24...   \n",
       "Decision Tree Classifier              [0.3280943025540275, 0.13214285714285715, 0.22...   \n",
       "Mutinomial NB                         [0.011787819253438114, 0.0, 0.0064794816414686...   \n",
       "Linear Support Vector Classification  [0.587426326129666, 0.14464285714285716, 0.355...   \n",
       "Random Forest Classifier              [0.3005893909626719, 0.06964285714285715, 0.17...   \n",
       "\n",
       "                                                                        Precision_score  \\\n",
       "Model                                                                                     \n",
       "Logistic Regresion                    [0.5770833333333333, 0.3, 0.3780687397708674, ...   \n",
       "Decision Tree Classifier              [0.3856812933025404, 0.2138728323699422, 0.230...   \n",
       "Mutinomial NB                         [1.0, 0.0, 0.09230769230769231, 0.119086460032...   \n",
       "Linear Support Vector Classification  [0.5368043087971275, 0.34913793103448276, 0.40...   \n",
       "Random Forest Classifier              [0.4751552795031056, 0.2932330827067669, 0.288...   \n",
       "\n",
       "                                                                               F1_score  \\\n",
       "Model                                                                                     \n",
       "Logistic Regresion                    [0.5601617795753286, 0.058064516129032254, 0.3...   \n",
       "Decision Tree Classifier              [0.3545647558386412, 0.16335540838852097, 0.22...   \n",
       "Mutinomial NB                         [0.023300970873786405, 0.0, 0.0121089808274470...   \n",
       "Linear Support Vector Classification  [0.5609756097560975, 0.20454545454545456, 0.37...   \n",
       "Random Forest Classifier              [0.3682310469314079, 0.11255411255411255, 0.21...   \n",
       "\n",
       "                                          Time  \n",
       "Model                                           \n",
       "Logistic Regresion                    0.003744  \n",
       "Decision Tree Classifier              0.003864  \n",
       "Mutinomial NB                         0.003270  \n",
       "Linear Support Vector Classification  0.004425  \n",
       "Random Forest Classifier              0.002815  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_results = pd.DataFrame((i for i in l) , columns=['Model','Accuracy_score', 'Recall_score','Precision_score','F1_score','Time'] )\n",
    "# df_results['Model'] = ['Logistic Regresion', 'Decision Tree Classifier', 'Mutinomial NB', 'Linear Support Vector Classification', 'Random Forest Classifier']\n",
    "# df_results = df_results.set_index('Model')\n",
    "# df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy_score</th>\n",
       "      <th>Recall_score</th>\n",
       "      <th>Precision_score</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regresion</th>\n",
       "      <td>60.0%</td>\n",
       "      <td>[0.5442043222003929, 0.03214285714285714, 0.24...</td>\n",
       "      <td>[0.5770833333333333, 0.3, 0.3780687397708674, ...</td>\n",
       "      <td>[0.5601617795753286, 0.058064516129032254, 0.3...</td>\n",
       "      <td>0.003055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>46.0%</td>\n",
       "      <td>[0.32023575638506874, 0.14464285714285716, 0.2...</td>\n",
       "      <td>[0.3738532110091743, 0.2125984251968504, 0.234...</td>\n",
       "      <td>[0.344973544973545, 0.17215727948990436, 0.226...</td>\n",
       "      <td>0.002815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mutinomial NB</th>\n",
       "      <td>47.0%</td>\n",
       "      <td>[0.011787819253438114, 0.0, 0.0064794816414686...</td>\n",
       "      <td>[1.0, 0.0, 0.09230769230769231, 0.119086460032...</td>\n",
       "      <td>[0.023300970873786405, 0.0, 0.0121089808274470...</td>\n",
       "      <td>0.002924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Support Vector Classification</th>\n",
       "      <td>61.0%</td>\n",
       "      <td>[0.587426326129666, 0.14464285714285716, 0.355...</td>\n",
       "      <td>[0.5368043087971275, 0.34913793103448276, 0.40...</td>\n",
       "      <td>[0.5609756097560975, 0.20454545454545456, 0.37...</td>\n",
       "      <td>0.003740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>53.0%</td>\n",
       "      <td>[0.3379174852652259, 0.07678571428571429, 0.16...</td>\n",
       "      <td>[0.4738292011019284, 0.2986111111111111, 0.283...</td>\n",
       "      <td>[0.39449541284403666, 0.12215909090909093, 0.2...</td>\n",
       "      <td>0.004091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Accuracy_score  \\\n",
       "Model                                                 \n",
       "Logistic Regresion                            60.0%   \n",
       "Decision Tree Classifier                      46.0%   \n",
       "Mutinomial NB                                 47.0%   \n",
       "Linear Support Vector Classification          61.0%   \n",
       "Random Forest Classifier                      53.0%   \n",
       "\n",
       "                                                                           Recall_score  \\\n",
       "Model                                                                                     \n",
       "Logistic Regresion                    [0.5442043222003929, 0.03214285714285714, 0.24...   \n",
       "Decision Tree Classifier              [0.32023575638506874, 0.14464285714285716, 0.2...   \n",
       "Mutinomial NB                         [0.011787819253438114, 0.0, 0.0064794816414686...   \n",
       "Linear Support Vector Classification  [0.587426326129666, 0.14464285714285716, 0.355...   \n",
       "Random Forest Classifier              [0.3379174852652259, 0.07678571428571429, 0.16...   \n",
       "\n",
       "                                                                        Precision_score  \\\n",
       "Model                                                                                     \n",
       "Logistic Regresion                    [0.5770833333333333, 0.3, 0.3780687397708674, ...   \n",
       "Decision Tree Classifier              [0.3738532110091743, 0.2125984251968504, 0.234...   \n",
       "Mutinomial NB                         [1.0, 0.0, 0.09230769230769231, 0.119086460032...   \n",
       "Linear Support Vector Classification  [0.5368043087971275, 0.34913793103448276, 0.40...   \n",
       "Random Forest Classifier              [0.4738292011019284, 0.2986111111111111, 0.283...   \n",
       "\n",
       "                                                                               F1_score  \\\n",
       "Model                                                                                     \n",
       "Logistic Regresion                    [0.5601617795753286, 0.058064516129032254, 0.3...   \n",
       "Decision Tree Classifier              [0.344973544973545, 0.17215727948990436, 0.226...   \n",
       "Mutinomial NB                         [0.023300970873786405, 0.0, 0.0121089808274470...   \n",
       "Linear Support Vector Classification  [0.5609756097560975, 0.20454545454545456, 0.37...   \n",
       "Random Forest Classifier              [0.39449541284403666, 0.12215909090909093, 0.2...   \n",
       "\n",
       "                                          Time  \n",
       "Model                                           \n",
       "Logistic Regresion                    0.003055  \n",
       "Decision Tree Classifier              0.002815  \n",
       "Mutinomial NB                         0.002924  \n",
       "Linear Support Vector Classification  0.003740  \n",
       "Random Forest Classifier              0.004091  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = table_results(l)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = [lg_multi_class, dt_multi_class, nb_multi_class , svc_multi_class, rf_multi_class ]\n",
    "df_recall_pre_f1 = df_results.loc[: ,['Recall_score' , 'Precision_score' , 'F1_score']]\n",
    "# df_r = df_t.explode('Recall_score')\n",
    "# df_p = df_t.explode('Precision_score')\n",
    "# df_new = df_t.explode('F1_score')\n",
    "# pd.concat([df_r, df_p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recall = table_manupulation(df_recall_pre_f1, 'Recall_score')\n",
    "precision = table_manupulation(df_recall_pre_f1, 'Precision_score')\n",
    "f1_score = table_manupulation(df_recall_pre_f1, 'F1_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrix = pd.DataFrame([recall, precision, f1_score]).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall_score</th>\n",
       "      <th>Precision_score</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>target_class</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.544204</td>\n",
       "      <td>0.577083</td>\n",
       "      <td>0.560162</td>\n",
       "      <td>1</td>\n",
       "      <td>Logistic Regresion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.032143</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.058065</td>\n",
       "      <td>2</td>\n",
       "      <td>Logistic Regresion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.249460</td>\n",
       "      <td>0.378069</td>\n",
       "      <td>0.300586</td>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regresion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.391646</td>\n",
       "      <td>0.474123</td>\n",
       "      <td>0.428956</td>\n",
       "      <td>4</td>\n",
       "      <td>Logistic Regresion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.674141</td>\n",
       "      <td>0.773017</td>\n",
       "      <td>5</td>\n",
       "      <td>Logistic Regresion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.320236</td>\n",
       "      <td>0.373853</td>\n",
       "      <td>0.344974</td>\n",
       "      <td>1</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.144643</td>\n",
       "      <td>0.212598</td>\n",
       "      <td>0.172157</td>\n",
       "      <td>2</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.218143</td>\n",
       "      <td>0.234611</td>\n",
       "      <td>0.226077</td>\n",
       "      <td>3</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.358722</td>\n",
       "      <td>0.341760</td>\n",
       "      <td>0.350036</td>\n",
       "      <td>4</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.660258</td>\n",
       "      <td>0.621724</td>\n",
       "      <td>0.640412</td>\n",
       "      <td>5</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.011788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023301</td>\n",
       "      <td>1</td>\n",
       "      <td>Mutinomial NB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>Mutinomial NB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.006479</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>0.012109</td>\n",
       "      <td>3</td>\n",
       "      <td>Mutinomial NB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.035872</td>\n",
       "      <td>0.119086</td>\n",
       "      <td>0.055136</td>\n",
       "      <td>4</td>\n",
       "      <td>Mutinomial NB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.998278</td>\n",
       "      <td>0.509296</td>\n",
       "      <td>0.674486</td>\n",
       "      <td>5</td>\n",
       "      <td>Mutinomial NB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.587426</td>\n",
       "      <td>0.536804</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>1</td>\n",
       "      <td>Linear Support Vector Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.144643</td>\n",
       "      <td>0.349138</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>2</td>\n",
       "      <td>Linear Support Vector Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.355292</td>\n",
       "      <td>0.402200</td>\n",
       "      <td>0.377294</td>\n",
       "      <td>3</td>\n",
       "      <td>Linear Support Vector Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.408845</td>\n",
       "      <td>0.497013</td>\n",
       "      <td>0.448638</td>\n",
       "      <td>4</td>\n",
       "      <td>Linear Support Vector Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.716580</td>\n",
       "      <td>0.786112</td>\n",
       "      <td>5</td>\n",
       "      <td>Linear Support Vector Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.337917</td>\n",
       "      <td>0.473829</td>\n",
       "      <td>0.394495</td>\n",
       "      <td>1</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.076786</td>\n",
       "      <td>0.298611</td>\n",
       "      <td>0.122159</td>\n",
       "      <td>2</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.169546</td>\n",
       "      <td>0.283906</td>\n",
       "      <td>0.212306</td>\n",
       "      <td>3</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.353808</td>\n",
       "      <td>0.385439</td>\n",
       "      <td>0.368947</td>\n",
       "      <td>4</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.822669</td>\n",
       "      <td>0.625027</td>\n",
       "      <td>0.710357</td>\n",
       "      <td>5</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Recall_score  Precision_score  F1_score  target_class  \\\n",
       "0       0.544204         0.577083  0.560162             1   \n",
       "1       0.032143         0.300000  0.058065             2   \n",
       "2       0.249460         0.378069  0.300586             3   \n",
       "3       0.391646         0.474123  0.428956             4   \n",
       "4       0.905882         0.674141  0.773017             5   \n",
       "5       0.320236         0.373853  0.344974             1   \n",
       "6       0.144643         0.212598  0.172157             2   \n",
       "7       0.218143         0.234611  0.226077             3   \n",
       "8       0.358722         0.341760  0.350036             4   \n",
       "9       0.660258         0.621724  0.640412             5   \n",
       "10      0.011788         1.000000  0.023301             1   \n",
       "11      0.000000         0.000000  0.000000             2   \n",
       "12      0.006479         0.092308  0.012109             3   \n",
       "13      0.035872         0.119086  0.055136             4   \n",
       "14      0.998278         0.509296  0.674486             5   \n",
       "15      0.587426         0.536804  0.560976             1   \n",
       "16      0.144643         0.349138  0.204545             2   \n",
       "17      0.355292         0.402200  0.377294             3   \n",
       "18      0.408845         0.497013  0.448638             4   \n",
       "19      0.870588         0.716580  0.786112             5   \n",
       "20      0.337917         0.473829  0.394495             1   \n",
       "21      0.076786         0.298611  0.122159             2   \n",
       "22      0.169546         0.283906  0.212306             3   \n",
       "23      0.353808         0.385439  0.368947             4   \n",
       "24      0.822669         0.625027  0.710357             5   \n",
       "\n",
       "                                   model  \n",
       "0                     Logistic Regresion  \n",
       "1                     Logistic Regresion  \n",
       "2                     Logistic Regresion  \n",
       "3                     Logistic Regresion  \n",
       "4                     Logistic Regresion  \n",
       "5               Decision Tree Classifier  \n",
       "6               Decision Tree Classifier  \n",
       "7               Decision Tree Classifier  \n",
       "8               Decision Tree Classifier  \n",
       "9               Decision Tree Classifier  \n",
       "10                         Mutinomial NB  \n",
       "11                         Mutinomial NB  \n",
       "12                         Mutinomial NB  \n",
       "13                         Mutinomial NB  \n",
       "14                         Mutinomial NB  \n",
       "15  Linear Support Vector Classification  \n",
       "16  Linear Support Vector Classification  \n",
       "17  Linear Support Vector Classification  \n",
       "18  Linear Support Vector Classification  \n",
       "19  Linear Support Vector Classification  \n",
       "20              Random Forest Classifier  \n",
       "21              Random Forest Classifier  \n",
       "22              Random Forest Classifier  \n",
       "23              Random Forest Classifier  \n",
       "24              Random Forest Classifier  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrix['target_class'] = pd.Series([1,2,3,4,5] * 5)\n",
    "repeat_model = pd.Series(['Logistic Regresion', 'Decision Tree Classifier', 'Mutinomial NB', 'Linear Support Vector Classification', 'Random Forest Classifier'])\n",
    "repeat_model = repeat_model.repeat(5).reset_index()\n",
    "df_metrix['model']  = repeat_model.drop(columns='index')\n",
    "df_metrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall_score</th>\n",
       "      <th>Precision_score</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>target_class</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.544204</td>\n",
       "      <td>0.577083</td>\n",
       "      <td>0.560162</td>\n",
       "      <td>1</td>\n",
       "      <td>Logistic Regresion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.032143</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.058065</td>\n",
       "      <td>2</td>\n",
       "      <td>Logistic Regresion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.249460</td>\n",
       "      <td>0.378069</td>\n",
       "      <td>0.300586</td>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regresion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.391646</td>\n",
       "      <td>0.474123</td>\n",
       "      <td>0.428956</td>\n",
       "      <td>4</td>\n",
       "      <td>Logistic Regresion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.674141</td>\n",
       "      <td>0.773017</td>\n",
       "      <td>5</td>\n",
       "      <td>Logistic Regresion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.326130</td>\n",
       "      <td>0.372197</td>\n",
       "      <td>0.347644</td>\n",
       "      <td>1</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.141071</td>\n",
       "      <td>0.215847</td>\n",
       "      <td>0.170626</td>\n",
       "      <td>2</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.233261</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.236583</td>\n",
       "      <td>3</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.360197</td>\n",
       "      <td>0.342844</td>\n",
       "      <td>0.351306</td>\n",
       "      <td>4</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.652798</td>\n",
       "      <td>0.620737</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>5</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.011788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023301</td>\n",
       "      <td>1</td>\n",
       "      <td>Mutinomial NB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>Mutinomial NB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.006479</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>0.012109</td>\n",
       "      <td>3</td>\n",
       "      <td>Mutinomial NB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.035872</td>\n",
       "      <td>0.119086</td>\n",
       "      <td>0.055136</td>\n",
       "      <td>4</td>\n",
       "      <td>Mutinomial NB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.998278</td>\n",
       "      <td>0.509296</td>\n",
       "      <td>0.674486</td>\n",
       "      <td>5</td>\n",
       "      <td>Mutinomial NB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.587426</td>\n",
       "      <td>0.536804</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>1</td>\n",
       "      <td>Linear Support Vector Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.144643</td>\n",
       "      <td>0.349138</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>2</td>\n",
       "      <td>Linear Support Vector Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.355292</td>\n",
       "      <td>0.402200</td>\n",
       "      <td>0.377294</td>\n",
       "      <td>3</td>\n",
       "      <td>Linear Support Vector Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.408845</td>\n",
       "      <td>0.497013</td>\n",
       "      <td>0.448638</td>\n",
       "      <td>4</td>\n",
       "      <td>Linear Support Vector Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.716580</td>\n",
       "      <td>0.786112</td>\n",
       "      <td>5</td>\n",
       "      <td>Linear Support Vector Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.277014</td>\n",
       "      <td>0.481229</td>\n",
       "      <td>0.351621</td>\n",
       "      <td>1</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.217687</td>\n",
       "      <td>0.090523</td>\n",
       "      <td>2</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.177106</td>\n",
       "      <td>0.286713</td>\n",
       "      <td>0.218959</td>\n",
       "      <td>3</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.344963</td>\n",
       "      <td>0.374400</td>\n",
       "      <td>0.359079</td>\n",
       "      <td>4</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.820086</td>\n",
       "      <td>0.617545</td>\n",
       "      <td>0.704548</td>\n",
       "      <td>5</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Recall_score  Precision_score  F1_score  target_class  \\\n",
       "0       0.544204         0.577083  0.560162             1   \n",
       "1       0.032143         0.300000  0.058065             2   \n",
       "2       0.249460         0.378069  0.300586             3   \n",
       "3       0.391646         0.474123  0.428956             4   \n",
       "4       0.905882         0.674141  0.773017             5   \n",
       "5       0.326130         0.372197  0.347644             1   \n",
       "6       0.141071         0.215847  0.170626             2   \n",
       "7       0.233261         0.240000  0.236583             3   \n",
       "8       0.360197         0.342844  0.351306             4   \n",
       "9       0.652798         0.620737  0.636364             5   \n",
       "10      0.011788         1.000000  0.023301             1   \n",
       "11      0.000000         0.000000  0.000000             2   \n",
       "12      0.006479         0.092308  0.012109             3   \n",
       "13      0.035872         0.119086  0.055136             4   \n",
       "14      0.998278         0.509296  0.674486             5   \n",
       "15      0.587426         0.536804  0.560976             1   \n",
       "16      0.144643         0.349138  0.204545             2   \n",
       "17      0.355292         0.402200  0.377294             3   \n",
       "18      0.408845         0.497013  0.448638             4   \n",
       "19      0.870588         0.716580  0.786112             5   \n",
       "20      0.277014         0.481229  0.351621             1   \n",
       "21      0.057143         0.217687  0.090523             2   \n",
       "22      0.177106         0.286713  0.218959             3   \n",
       "23      0.344963         0.374400  0.359079             4   \n",
       "24      0.820086         0.617545  0.704548             5   \n",
       "\n",
       "                                   model  \n",
       "0                     Logistic Regresion  \n",
       "1                     Logistic Regresion  \n",
       "2                     Logistic Regresion  \n",
       "3                     Logistic Regresion  \n",
       "4                     Logistic Regresion  \n",
       "5               Decision Tree Classifier  \n",
       "6               Decision Tree Classifier  \n",
       "7               Decision Tree Classifier  \n",
       "8               Decision Tree Classifier  \n",
       "9               Decision Tree Classifier  \n",
       "10                         Mutinomial NB  \n",
       "11                         Mutinomial NB  \n",
       "12                         Mutinomial NB  \n",
       "13                         Mutinomial NB  \n",
       "14                         Mutinomial NB  \n",
       "15  Linear Support Vector Classification  \n",
       "16  Linear Support Vector Classification  \n",
       "17  Linear Support Vector Classification  \n",
       "18  Linear Support Vector Classification  \n",
       "19  Linear Support Vector Classification  \n",
       "20              Random Forest Classifier  \n",
       "21              Random Forest Classifier  \n",
       "22              Random Forest Classifier  \n",
       "23              Random Forest Classifier  \n",
       "24              Random Forest Classifier  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# df_r = df_recall_pre_f1.explode('Recall_score')\n",
    "# recall = df_r.loc[ : , 'Recall_score']\n",
    "# x = recall.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# df_p = df_recall_pre_f1.explode('Precision_score')\n",
    "# precission = df_p.loc[ : , 'Precision_score']\n",
    "# m = precission.reset_index(drop= True)\n",
    "\n",
    "df_f = df_recall_pre_f1.explode('F1_score')\n",
    "# f1_score = df_f.loc[ : , 'F1_score']\n",
    "# k = f1_score.reset_index(drop=True)\n",
    "# df_metrix = pd.DataFrame([x, m, k]).transpose()\n",
    "# # df_metrix['class'] = [1,2,3,4,5]\n",
    "# df_metrix\n",
    "\n",
    "# class_target = pd.Series([1,2,3,4,5] * 5)\n",
    "# class_target\n",
    "# # repeat_class_target = class_target.repeat(5)\n",
    "# # repeat_class_target\n",
    "# df_metrix['target_class'] = pd.Series([1,2,3,4,5] * 5)\n",
    "\n",
    "\n",
    "# repeat_model = pd.Series(['Logistic Regresion', 'Decision Tree Classifier', 'Mutinomial NB', 'Linear Support Vector Classification', 'Random Forest Classifier'])\n",
    "\n",
    "# repeat_model = repeat_model.repeat(5).reset_index()\n",
    "# df_metrix['model']  = repeat_model.drop(columns='index')\n",
    "# tt = df_metrix.groupby(['model'] ,as_index=False)\n",
    "\n",
    "# grouped = df_metrix.reset_index().groupby(by=['model'])\n",
    "\n",
    "# df_metrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters tunning in classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_grid(model ,col,col1, parameteres):  \n",
    "    start = timeit.timeit()\n",
    "    \"\"\"It takes two columns and a classifier, split the data into traing and testing, vectorize it, remove irrlevant features using and implemnt a ca\n",
    "    classifier using a pipeline,then implenet Grid Search and return a dictionary with accuracy, precions and recall f_1 socre and running time\"\"\"\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['Reviews_tokenize_join'] ,df['target'], test_size=0.3, random_state = 42)\n",
    "\n",
    "    pipeline = Pipeline([('vect', TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\", sublinear_tf=True)),\n",
    "                         ('chi',  SelectKBest(chi2, k=10000)),\n",
    "                         ('clf', model)])\n",
    "    \n",
    "    grid = GridSearchCV(pipeline, param_grid=parameteres, cv=5)\n",
    "    grid.fit(X_train, y_train)\n",
    "#     m_best = grid.best_estimator_ maybe used?\n",
    "    y_pred = m_best.predict(X_test)\n",
    "\n",
    "    end = timeit.timeit()\n",
    "    final_time = start - end\n",
    "\n",
    "    list_names = ['Model','Accuracy_score','Recall_score','Precision_score','F1_score', 'Time']\n",
    "    score_list = []\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred,average=None, pos_label='Good')\n",
    "    precision = precision_score(y_test, y_pred,average=None, pos_label='Good')\n",
    "    f_1 = f1_score(y_test , y_pred,average=None, pos_label='Good')\n",
    "#     roc_auc = metrics.roc_auc_score(y_test, preds)\n",
    "    final_time = start - end\n",
    "\n",
    "    score_list.extend([model,accuracy,recall,precision,f_1,final_time])\n",
    "    dictionary = dict(zip(list_names, score_list))\n",
    "    return dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion with GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_multi_grid = clf_grid(LogisticRegression(),'Reviews_tokenize_join', 'target',parameteres = {'clf__C':[0.01, 0.1, 1, 10, 100] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'Accuracy_score': 0.6127744510978044,\n",
       " 'Recall_score': array([0.5481336 , 0.15714286, 0.39416847, 0.42948403, 0.86054519]),\n",
       " 'Precision_score': array([0.5625    , 0.34509804, 0.42491269, 0.50432776, 0.71883988]),\n",
       " 'F1_score': array([0.55522388, 0.21595092, 0.40896359, 0.46390658, 0.78333551]),\n",
       " 'Time': 0.001937517999863303}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_multi_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.ensemble import RandomForestClassifier\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.5958749168330006\n",
      "Best parameters : {'clf__alpha': 0.5, 'clf__fit_prior': False}\n"
     ]
    }
   ],
   "source": [
    "nb_muti_grid = clf_grid(MultinomialNB(),'Reviews_tokenize_join', 'target', parameteres = {'clf__alpha': np.linspace(0.5, 1.5, 6), 'clf__fit_prior': [True, False]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_muti_grid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.5076513639387891\n",
      "Best parameters : {'clf__criterion': 'gini', 'clf__max_depth': 6, 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "dt_multi_grid = clf_grid(DecisionTreeClassifier(),'Reviews_tokenize_join', 'target',parameteres = {\n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "    'clf__max_depth': [None, 2, 3, 4, 5, 6],\n",
    "    'clf__min_samples_split': [2, 5, 10],\n",
    "    'clf__min_samples_leaf': [1, 2, 3, 4, 5, 6]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_multi_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_multi_grid = clf_grid(RandomForestClassifier(),'Reviews_tokenize_join', 'target', parameteres = {\n",
    "    'clf__n_estimators': [10, 30, 100],\n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "    'clf__max_depth': [None, 2, 6, 10],\n",
    "    'clf__min_samples_split': [5, 10],\n",
    "    'clf__min_samples_leaf': [3, 6]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_multi_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Linear Support Vector Classification with GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.5984031936127745\n",
      "Best parameters : {'clf__C': 0.1, 'clf__max_iter': 1000}\n"
     ]
    }
   ],
   "source": [
    "svc_multi_grid = clf_grid(LinearSVC(), 'Reviews_tokenize_join', 'target' ,parameteres = {'clf__C':[0.001,0.1,10,100,10e5], 'clf__max_iter':[1000, 2000,3000]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_multi_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change target to 3 categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First model needs to be improved.\n",
    "There are a lot more 4, 5 stars than 1, 2, 3 stars,\n",
    "Set 1, 2, 3 stars to 'Bad', 4 stars to 'Neutral', 5 stars to 'Good'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tree_categories = df.replace({5: 'good', 4: 'neutral', 3: 'bad' , 2: 'bad', 1: 'bad'})\n",
    "# df_tree_categories.head()\n",
    "df['tri_target'] = 'Bad'\n",
    "df.loc[df['review_rating'] == 5, 'tri_target'] = 'Good'\n",
    "df.loc[df['review_rating'] == 4, 'tri_target'] = 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good       11878\n",
       "Neutral     6622\n",
       "Bad         6550\n",
       "Name: tri_target, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tri_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a191a9048>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_tree_categories['target'].plot.bar(bins=12, alpha=0.5)\n",
    "df['tri_target'].value_counts().sort_values().plot(kind = 'barh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Logistic Regressiom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_tri_class =clf( LogisticRegression(), 'Reviews_tokenize_join', 'tri_target')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'Accuracy_score': 0.7161676646706587,\n",
       " 'Recall_score': array([0.81954887, 0.88579627, 0.32432432]),\n",
       " 'Precision_score': array([0.80225711, 0.71491431, 0.56945643]),\n",
       " 'F1_score': array([0.81081081, 0.79123414, 0.41327489]),\n",
       " 'Time': 0.002936557999873912}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld_tri_class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best') , Time: 0.004610341005900409\n",
      "Accuracy: 53.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.61      0.50      0.55      1995\n",
      "        good       0.61      0.66      0.64      3485\n",
      "     neutral       0.33      0.35      0.34      2035\n",
      "\n",
      "    accuracy                           0.53      7515\n",
      "   macro avg       0.52      0.50      0.51      7515\n",
      "weighted avg       0.54      0.53      0.53      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_tri_class = clf(DecisionTreeClassifier(), 'Reviews_tokenize_join', 'tri_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_tri_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) , Time: 0.0046771149936830625\n",
      "Accuracy: 65.38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.87      0.68      0.77      1995\n",
      "        good       0.60      0.98      0.75      3485\n",
      "     neutral       0.47      0.06      0.11      2035\n",
      "\n",
      "    accuracy                           0.65      7515\n",
      "   macro avg       0.65      0.58      0.54      7515\n",
      "weighted avg       0.64      0.65      0.58      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_tri_class = clf(MultinomialNB(), 'Reviews_tokenize_join', 'tri_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_tri_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine with stochastic gradient descent (SGD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False) , Time: 0.004174531000899151\n",
      "Accuracy: 70.39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.73      0.89      0.81      1995\n",
      "        good       0.69      0.94      0.80      3485\n",
      "     neutral       0.68      0.11      0.20      2035\n",
      "\n",
      "    accuracy                           0.70      7515\n",
      "   macro avg       0.70      0.65      0.60      7515\n",
      "weighted avg       0.70      0.70      0.64      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_tri_class= clf(SGDClassifier(), 'Reviews_tokenize_join', 'tri_target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) , Time: 0.003260140001657419\n",
      "Accuracy: 71.32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.79      0.83      0.81      1995\n",
      "        good       0.74      0.85      0.79      3485\n",
      "     neutral       0.53      0.36      0.43      2035\n",
      "\n",
      "    accuracy                           0.71      7515\n",
      "   macro avg       0.69      0.68      0.68      7515\n",
      "weighted avg       0.69      0.71      0.70      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_tri_class = clf(LinearSVC(), 'Reviews_tokenize_join', 'tri_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_tri_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False) , Time: 0.004170633001194801\n",
      "Accuracy: 62.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.74      0.62      0.67      1995\n",
      "        good       0.63      0.89      0.73      3485\n",
      "     neutral       0.43      0.19      0.26      2035\n",
      "\n",
      "    accuracy                           0.63      7515\n",
      "   macro avg       0.60      0.57      0.56      7515\n",
      "weighted avg       0.60      0.63      0.59      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_tri_class = clf(RandomForestClassifier(), 'Reviews_tokenize_join', 'tri_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tri_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunning hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loigistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.7161676646706587\n",
      "Best parameters : {'clf__C': 1, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "lg_tri_grid = clf_grid(LogisticRegression(),'Reviews_tokenize_join', 'tri_target', parameteres ={'clf__penalty' : ['l1', 'l2'],\n",
    "# 'clf__C' : [ 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "# 'clf__solver': ['liblinear', 'saga']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.7161676646706587\n",
      "Best parameters : {'clf__C': 1}\n"
     ]
    }
   ],
   "source": [
    "clf_grid(df_tree_categories, LogisticRegression(),'Reviews_tokenize_join', 'tri_target',parameters_lg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_tri_grid = clf_grid( DecisionTreeClassifier(),'Reviews_tokenize_join', 'tri_target', parameteres = {\n",
    "#     'clf__criterion': ['gini', 'entropy'],\n",
    "#     'clf__max_depth': [None, 2, 3, 4, 5, 6],\n",
    "#     'clf__min_samples_split': [2, 5, 10],\n",
    "#     'clf__min_samples_leaf': [1, 2, 3, 4, 5, 6]\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.ensemble import RandomForestClassifier\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.7153692614770459\n",
      "Best parameters : {'clf__alpha': 0.5, 'clf__fit_prior': False}\n"
     ]
    }
   ],
   "source": [
    "nb_tri_grid = clf_grid( MultinomialNB(),'Reviews_tokenize_join', 'tri_target', parameteres = {'clf__alpha': np.linspace(0.5, 1.5, 6), 'clf__fit_prior': [True, False]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.7166999334664005\n",
      "Best parameters : {'clf__C': 0.1, 'clf__max_iter': 1000}\n"
     ]
    }
   ],
   "source": [
    "svc_tri_grid = clf_grid( LinearSVC() , 'Reviews_tokenize_join', 'tri_target',parameteres = {'clf__C':[0.001,0.1,10,100,10e5], 'clf__max_iter':[1000, 2000,3000]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tri_grid = clf_grid( RandomForestClassifier(), 'Reviews_tokenize_join', 'tri_target', parameteres = {\n",
    "#     'clf__n_estimators': [10, 30, 100],\n",
    "#     'clf__criterion': ['gini', 'entropy'],\n",
    "#     'clf__max_depth': [None, 2, 6, 10],\n",
    "#     'clf__min_samples_split': [5, 10],\n",
    "#     'clf__min_samples_leaf': [3, 6]\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change target to 2 categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last model is not bad but I think It can improve if I implement binary classification.\n",
    "Divide the df into 5 stars as Good and the rest as Bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bi_target'] = 'Bad'\n",
    "df.loc[df['review_rating'] == 5, 'bi_target'] = 'Good'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_rating</th>\n",
       "      <th>Reviews_tokenize_join</th>\n",
       "      <th>target</th>\n",
       "      <th>tri_target</th>\n",
       "      <th>binamial_target</th>\n",
       "      <th>bi_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>start say understand hard time city country en...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>wonderful visit time park view thank upgrade l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>good hotel stay absolutely worth money view ce...</td>\n",
       "      <td>5</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>fantastic location spot step central park view...</td>\n",
       "      <td>5</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>amazing park view nicole staff professional fr...</td>\n",
       "      <td>5</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_rating                              Reviews_tokenize_join target  \\\n",
       "0              1  start say understand hard time city country en...      1   \n",
       "1              5  wonderful visit time park view thank upgrade l...      5   \n",
       "2              5  good hotel stay absolutely worth money view ce...      5   \n",
       "3              5  fantastic location spot step central park view...      5   \n",
       "4              5  amazing park view nicole staff professional fr...      5   \n",
       "\n",
       "  tri_target binamial_target bi_target  \n",
       "0        Bad             Bad       Bad  \n",
       "1       Good            Good      Good  \n",
       "2       Good            Good      Good  \n",
       "3       Good            Good      Good  \n",
       "4       Good            Good      Good  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.binamial_target.value_counts(normalize = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1c0cd828>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['bi_target'].value_counts().sort_values().plot(kind = 'barh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Engineering and Modelling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_bi_class = clf(LogisticRegression(), 'Reviews_tokenize_join', 'bi_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_bi_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_bi_class = clf(DecisionTreeClassifier(), 'Reviews_tokenize_join', 'bi_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_bi_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinoial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) , Time: 0.003956167995056603\n",
      "Accuracy: 80.41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.83      0.80      0.81      4030\n",
      "        Good       0.78      0.81      0.79      3485\n",
      "\n",
      "    accuracy                           0.80      7515\n",
      "   macro avg       0.80      0.80      0.80      7515\n",
      "weighted avg       0.81      0.80      0.80      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_bi_class = clf(MultinomialNB(), 'Reviews_tokenize_join', 'bi_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_bi_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False) , Time: 0.0029596269960165955\n",
      "Accuracy: 80.56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.84      0.79      0.81      4030\n",
      "        Good       0.77      0.82      0.80      3485\n",
      "\n",
      "    accuracy                           0.81      7515\n",
      "   macro avg       0.81      0.81      0.81      7515\n",
      "weighted avg       0.81      0.81      0.81      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_bi_class = clf(SGDClassifier(), 'Reviews_tokenize_join', 'bi_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_bi_class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) , Time: 0.003953686995373573\n",
      "Accuracy: 80.49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.83      0.79      0.81      4030\n",
      "        Good       0.77      0.82      0.80      3485\n",
      "\n",
      "    accuracy                           0.80      7515\n",
      "   macro avg       0.80      0.81      0.80      7515\n",
      "weighted avg       0.81      0.80      0.81      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_bi_class = clf(LinearSVC(), 'Reviews_tokenize_join', 'bi_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_bi_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_bi_grid = clf_grid( RandomForestClassifier(), 'Reviews_tokenize_join', 'bi_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_bi_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunning hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_bi_grid = clf_grid(LogisticRegression(),'Reviews_tokenize_join', 'bi_target', parameteres ={'clf__penalty' : ['l1', 'l2'],\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_bi_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_bi_grid = clf_grid( DecisionTreeClassifier(),'Reviews_tokenize_join', 'bi_target', parameteres = {\n",
    "#     'clf__criterion': ['gini', 'entropy'],\n",
    "#     'clf__max_depth': [None, 2, 3, 4, 5, 6],\n",
    "#     'clf__min_samples_split': [2, 5, 10],\n",
    "#     'clf__min_samples_leaf': [1, 2, 3, 4, 5, 6]\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_bi_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_bi_grid = clf_grid( MultinomialNB(),'Reviews_tokenize_join', 'bi_target', parameteres = {'clf__alpha': np.linspace(0.5, 1.5, 6), 'clf__fit_prior': [True, False]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_bi_grid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_bi_grid = clf_grid( LinearSVC() , 'Reviews_tokenize_join', 'bi_target',parameteres = {'clf__C':[0.001,0.1,10,100,10e5], 'clf__max_iter':[1000, 2000,3000]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_bi_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_bi_grid = clf_grid( RandomForestClassifier(), 'Reviews_tokenize_join', 'bi_target', parameteres = {\n",
    "#     'clf__n_estimators': [10, 30, 100],\n",
    "#     'clf__criterion': ['gini', 'entropy'],\n",
    "#     'clf__max_depth': [None, 2, 6, 10],\n",
    "#     'clf__min_samples_split': [5, 10],\n",
    "#     'clf__min_samples_leaf': [3, 6]\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_bi_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Reviews_tokenize_join'] ,df['target'], test_size=0.3, random_state = 42)\n",
    "\n",
    "pipeline = Pipeline([('vect', TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\", sublinear_tf=True)),\n",
    "                     ('chi',  SelectKBest(chi2, k=10000)),\n",
    "                     ('clf', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameteres = {'clf__C':[0.001,0.1,10,100,10e5], 'clf__max_iter':[1000, 2000,3000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipeline, param_grid=parameteres, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words...\n",
       "                                                  dual=True, fit_intercept=True,\n",
       "                                                  intercept_scaling=1,\n",
       "                                                  loss='squared_hinge',\n",
       "                                                  max_iter=1000,\n",
       "                                                  multi_class='ovr',\n",
       "                                                  penalty='l2',\n",
       "                                                  random_state=None, tol=0.0001,\n",
       "                                                  verbose=0))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'clf__C': [0.001, 0.1, 10, 100, 1000000.0],\n",
       "                         'clf__max_iter': [1000, 2000, 3000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6217564870259481\n"
     ]
    }
   ],
   "source": [
    "print(grid.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 0.1, 'clf__max_iter': 1000}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score: 56.49%\n",
      "Classier:LinearSVC(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,\n",
      "          verbose=0) , Time: 0.0035134449990437133\n",
      "Accuracy: 0.5720558882235529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.49      0.50       509\n",
      "           2       0.33      0.03      0.05       560\n",
      "           3       0.35      0.12      0.17       926\n",
      "           4       0.42      0.35      0.38      2035\n",
      "           5       0.65      0.92      0.76      3485\n",
      "\n",
      "    accuracy                           0.57      7515\n",
      "   macro avg       0.45      0.38      0.37      7515\n",
      "weighted avg       0.52      0.57      0.51      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf(LinearSVC(C=0.1, penalty='l1', max_iter=1000, dual=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score: 59.54%\n",
      "Classier:LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) , Time: 0.004986515999917174\n",
      "Accuracy: 0.5984031936127745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.61      0.57       509\n",
      "           2       0.40      0.04      0.08       560\n",
      "           3       0.40      0.23      0.29       926\n",
      "           4       0.48      0.37      0.41      2035\n",
      "           5       0.67      0.92      0.77      3485\n",
      "\n",
      "    accuracy                           0.60      7515\n",
      "   macro avg       0.50      0.43      0.43      7515\n",
      "weighted avg       0.56      0.60      0.55      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf(LinearSVC(C=0.1, max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score: 60.98%\n",
      "Classier:LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) , Time: 0.006638550999923609\n",
      "Accuracy: 0.6087824351297405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.59      0.56       509\n",
      "           2       0.35      0.14      0.20       560\n",
      "           3       0.40      0.36      0.38       926\n",
      "           4       0.50      0.41      0.45      2035\n",
      "           5       0.72      0.87      0.79      3485\n",
      "\n",
      "    accuracy                           0.61      7515\n",
      "   macro avg       0.50      0.47      0.48      7515\n",
      "weighted avg       0.58      0.61      0.59      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf(LinearSVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.6171656686626746\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy score: \" + str(model.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = model.named_steps['vect']\n",
    "chi = model.named_steps['chi']\n",
    "clf = model.named_steps['classifier']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nfrom sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['aand price', 'able coffee', 'able comfortable', 'able complain',\n",
       "       'able cook', 'able manually', 'able rebook', 'able suitcase',\n",
       "       'able text', 'able toilet'], dtype='<U28')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_names = [feature_names[i] for i in chi.get_support(indices=True)]\n",
    "feature_names = np.asarray(feature_names)\n",
    "feature_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 keywords per class:\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nfrom sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: total cost horrible ruin uncleaned experience superb avoid cost stay away disgusting bed uncomfortable bad\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nfrom sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: work leak sink didn book site like hadn rudest shoddy wasn worth soil feel dirty maze\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nfrom sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: room rude average average experience worth lobby date staff tall building pro despite request problem need leave floor\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nfrom sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: attend opera lobby large good reasonable overall location downside reason didn simple clean excellent right general good drawback\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nfrom sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5: perfect love worth penny andrew grateful absolutely stay emanuel exceed impressed overall excellent\n"
     ]
    }
   ],
   "source": [
    "target_names = ['1', '2', '3', '4', '5']\n",
    "print(\"top 10 keywords per class:\")\n",
    "for i, label in enumerate(target_names):\n",
    "    top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "    print(\"%s: %s\" % (label, \" \".join(feature_names[top10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## limpiar la data quetar names como did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
