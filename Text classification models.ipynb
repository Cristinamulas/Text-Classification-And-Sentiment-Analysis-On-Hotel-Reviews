{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "import timeit\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_for_model.csv', usecols = ['review_rating' , 'Reviews_tokenize_join'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimazation memory by converting the review_rating to category\n",
    "df['target'] = df['review_rating'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x102dd6710>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD4CAYAAAAtrdtxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAWAUlEQVR4nO3dfbRldX3f8ffHGRR8HJTRkBnIkGakQZdWnCAprbGgMBDDkBbbsVZHi5k2wfjUtSLYrJBq6NLV1FFq1GCgGYgKiA9MDErGp7i6VgQHpQIicBdauEJldBBMUOjot3+c3zWH67kz5+6555x7ve/XWmfdvX/7t8/+nh/c+dz9cPZOVSFJUhePmnQBkqSlyxCRJHVmiEiSOjNEJEmdGSKSpM5WTrqAcTvssMNq3bp1ky5DkpaU66+//jtVtXp2+7ILkXXr1rFr165JlyFJS0qS/zOo3cNZkqTODBFJUmeGiCSps5GFSJKLk9yb5Ka+tv+W5OtJvprkY0lW9S07N8lUkluTnNLXvrG1TSU5p6/9qCTXJrk9yeVJHj2qzyJJGmyUeyJ/Dmyc1bYTeGZVPQu4DTgXIMkxwGbgGW2d9yRZkWQF8CfAqcAxwEtbX4C3A9uqaj1wH3DWCD+LJGmAkYVIVX0B2DOr7a+ram+b/SKwtk1vAi6rqoeq6hvAFHBce01V1R1V9TBwGbApSYATgSvb+tuBM0b1WSRJg03ynMi/Bz7ZptcAd/Utm25tc7U/BfheXyDNtEuSxmgiIZLkPwN7gQ/MNA3oVh3a59re1iS7kuzavXv3fMuVJM1h7CGSZAvwYuBl9Q8PM5kGjujrtha4ex/t3wFWJVk5q32gqrqwqjZU1YbVq3/qC5eSpI7G+o31JBuBNwG/VlUP9i3aAXwwyTuAnwfWA9fR2+NYn+Qo4Fv0Tr7/26qqJJ8DzqR3nmQLcNX4PokkLZxtO28b+Tbe8KKnj+R9R3mJ74eAvwWOTjKd5Czg3cATgJ1JbkjyPoCquhm4Avga8Cng7Kr6UTvn8RrgGuAW4IrWF3ph9MYkU/TOkVw0qs8iSRpsZHsiVfXSAc1z/kNfVecD5w9ovxq4ekD7HfSu3pIkTYjfWJckdWaISJI6M0QkSZ0ZIpKkzgwRSVJnhogkqTNDRJLUmSEiSerMEJEkdWaISJI6M0QkSZ0ZIpKkzgwRSVJnhogkqTNDRJLUmSEiSerMEJEkdWaISJI6M0QkSZ0ZIpKkzgwRSVJnhogkqTNDRJLUmSEiSerMEJEkdWaISJI6G1mIJLk4yb1Jbupre3KSnUlubz8Pbe1JckGSqSRfTXJs3zpbWv/bk2zpa39ukhvbOhckyag+iyRpsFHuifw5sHFW2znAZ6pqPfCZNg9wKrC+vbYC74Ve6ADnAc8DjgPOmwme1mdr33qztyVJGrGRhUhVfQHYM6t5E7C9TW8Hzuhrv6R6vgisSnI4cAqws6r2VNV9wE5gY1v2xKr626oq4JK+95Ikjcm4z4k8raruAWg/n9ra1wB39fWbbm37ap8e0D5Qkq1JdiXZtXv37gP+EJKknsVyYn3Q+Yzq0D5QVV1YVRuqasPq1as7lihJmm3cIfLtdiiK9vPe1j4NHNHXby1w937a1w5olySN0bhDZAcwc4XVFuCqvvZXtKu0jgfub4e7rgFOTnJoO6F+MnBNW/b9JMe3q7Je0fdekqQxWTmqN07yIeAFwGFJpuldZfU24IokZwF3Ai9p3a8GTgOmgAeBVwFU1Z4kbwW+1Pq9papmTtb/Nr0rwA4BPtlekqQxGlmIVNVL51h00oC+BZw9x/tcDFw8oH0X8MwDqVGSdGAWy4l1SdISZIhIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjqbSIgkeUOSm5PclORDSQ5OclSSa5PcnuTyJI9ufR/T5qfa8nV973Nua781ySmT+CyStJyNPUSSrAFeC2yoqmcCK4DNwNuBbVW1HrgPOKutchZwX1X9ErCt9SPJMW29ZwAbgfckWTHOzyJJy92kDmetBA5JshJ4LHAPcCJwZVu+HTijTW9q87TlJyVJa7+sqh6qqm8AU8BxY6pfksQEQqSqvgX8MXAnvfC4H7ge+F5V7W3dpoE1bXoNcFdbd2/r/5T+9gHrPEKSrUl2Jdm1e/fuhf1AkrSMTeJw1qH09iKOAn4eeBxw6oCuNbPKHMvmav/pxqoLq2pDVW1YvXr1/IuWJA00icNZLwS+UVW7q+r/AR8F/imwqh3eAlgL3N2mp4EjANryJwF7+tsHrCNJGoNJhMidwPFJHtvObZwEfA34HHBm67MFuKpN72jztOWfrapq7Zvb1VtHAeuB68b0GSRJ9E5wj1VVXZvkSuDLwF7gK8CFwF8BlyX5o9Z2UVvlIuDSJFP09kA2t/e5OckV9AJoL3B2Vf1orB9Gkpa5sYcIQFWdB5w3q/kOBlxdVVU/BF4yx/ucD5y/4AVKkobiN9YlSZ0NFSJJnjnqQiRJS8+weyLvS3Jdkt9JsmqkFUmSloyhQqSq/hnwMnqX1O5K8sEkLxppZZKkRW/ocyJVdTvw+8CbgF8DLkjy9ST/clTFSZIWt2HPiTwryTbgFnr3uPqNqvrlNr1thPVJkhaxYS/xfTfwfuDNVfWDmcaqujvJ74+kMknSojdsiJwG/GDmy3xJHgUcXFUPVtWlI6tOkrSoDXtO5NPAIX3zj21tkqRlbNgQObiq/m5mpk0/djQlSZKWimFD5O+THDszk+S5wA/20V+StAwMe07k9cCHk8zcav1w4N+MpiRJ0lIxVIhU1ZeS/GPgaHoPg/p6exaIJGkZm89dfH8FWNfWeU4SquqSkVQlSVoShgqRJJcC/wi4AZh5ZkcBhogkLWPD7olsAI5pTxSUJAkY/uqsm4CfG2UhkqSlZ9g9kcOAryW5DnhoprGqTh9JVZKkJWHYEPnDURYhSfO1bedtY9nOG1709LFsZ6ka9hLfv0nyC8D6qvp0kscCK0ZbmiRpsRv2VvC/BVwJ/GlrWgN8fFRFSZKWhmFPrJ8NnAA8AD95QNVTR1WUJGlpGDZEHqqqh2dmkqyk9z0RSdIyNmyI/E2SNwOHtGerfxj4y9GVJUlaCoYNkXOA3cCNwH8Arqb3vHVJ0jI27NVZP6b3eNz3j7YcSdJSMuzVWd9IcsfsV9eNJlmV5MokX09yS5JfTfLkJDuT3N5+Htr6JskFSaaSfHXWc022tP63J9nStR5JUjfzuXfWjIOBlwBPPoDtvgv4VFWdmeTR9J6S+GbgM1X1tiTn0DuE9ibgVGB9ez0PeC/wvCRPBs5rtRVwfZIdVXXfAdQlSZqHofZEquq7fa9vVdU7gRO7bDDJE4HnAxe19364qr4HbAK2t27bgTPa9Cbgkur5IrAqyeHAKcDOqtrTgmMnsLFLTZKkboa9FfyxfbOPovfX/xM6bvMX6Z2k/59Jng1cD7wOeFpV3QNQVfckmfkeyhrgrr71p1vbXO2D6t8KbAU48sgjO5YtSZpt2MNZ/71vei/wTeBfH8A2jwV+t6quTfIueoeu5pIBbbWP9p9urLoQuBBgw4YNfr9FkhbIsFdn/YsF3OY0MF1V17b5K+mFyLeTHN72Qg4H7u3rf0Tf+muBu1v7C2a1f34B65Qk7cewh7PeuK/lVfWOYTdYVf83yV1Jjq6qW4GTgK+11xbgbe3nVW2VHcBrklxG78T6/S1orgH+68xVXMDJwLnD1iFJOnDzuTrrV+j9gw7wG8AXeOQ5ifn4XeAD7cqsO4BX0TvXckWSs4A76V0BBr0vNp4GTAEPtr5U1Z4kbwW+1Pq9par2dKxHktTBfB5KdWxVfR8gyR8CH66qV3fZaFXdwCMvG55x0oC+Re8GkIPe52Lg4i41SJIO3LC3PTkSeLhv/mFg3YJXI0laUobdE7kUuC7Jx+hdAfWbwCUjq0qStCQMe3XW+Uk+Cfzz1vSqqvrK6MqSJC0Fwx7Ogt6tSR6oqncB00mOGlFNkqQlYtgbMJ5H7z5WM5fQHgT8xaiKkiQtDcPuifwmcDrw9wBVdTfdb3siSfoZMWyIPNwutS2AJI8bXUmSpKVi2BC5Ismf0ruD7m8Bn8YHVEnSsjfs1Vl/3J6t/gBwNPAHVbVzpJVJkha9/YZIkhXANVX1QnrP7JAkCRjicFZV/Qh4MMmTxlCPJGkJGfYb6z8Ebkyyk3aFFkBVvXYkVUmSloRhQ+Sv2kuSpJ/YZ4gkObKq7qyq7fvqJ0lanvZ3TuTjMxNJPjLiWiRJS8z+QqT/Oea/OMpCJElLz/5CpOaYliRpvyfWn53kAXp7JIe0adp8VdUTR1qdJGlR22eIVNWKcRUiSVp65vM8EUmSHsEQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSps4mFSJIVSb6S5BNt/qgk1ya5PcnlSR7d2h/T5qfa8nV973Fua781ySmT+SSStHxNck/kdcAtffNvB7ZV1XrgPuCs1n4WcF9V/RKwrfUjyTHAZuAZwEbgPe0pjJKkMZlIiCRZC/w68GdtPsCJwJWty3bgjDa9qc3Tlp/U+m8CLquqh6rqG8AUcNx4PoEkCSa3J/JO4PeAH7f5pwDfq6q9bX4aWNOm1wB3AbTl97f+P2kfsM4jJNmaZFeSXbt3717IzyFJy9rYQyTJi4F7q+r6/uYBXWs/y/a1ziMbqy6sqg1VtWH16tXzqleSNLdhH4+7kE4ATk9yGnAw8ER6eyarkqxsextrgbtb/2ngCGA6yUrgScCevvYZ/etIksZg7HsiVXVuVa2tqnX0Tox/tqpeBnwOOLN12wJc1aZ3tHna8s9WVbX2ze3qraOA9cB1Y/oYkiQmsycylzcBlyX5I+ArwEWt/SLg0iRT9PZANgNU1c1JrgC+BuwFzq6qH42/bElaviYaIlX1eeDzbfoOBlxdVVU/BF4yx/rnA+ePrkJJ0r74jXVJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSps8V07yxpWdu287aRb+MNL3r6yLeh5cU9EUlSZ4aIJKkzQ0SS1JkhIknqzBCRJHVmiEiSOjNEJEmdGSKSpM4MEUlSZ4aIJKkzQ0SS1JkhIknqzBCRJHVmiEiSOjNEJEmdjT1EkhyR5HNJbklyc5LXtfYnJ9mZ5Pb289DWniQXJJlK8tUkx/a915bW//YkW8b9WSRpuZvEnshe4D9V1S8DxwNnJzkGOAf4TFWtBz7T5gFOBda311bgvdALHeA84HnAccB5M8EjSRqPsYdIVd1TVV9u098HbgHWAJuA7a3bduCMNr0JuKR6vgisSnI4cAqws6r2VNV9wE5g4xg/iiQtexM9J5JkHfAc4FrgaVV1D/SCBnhq67YGuKtvtenWNlf7oO1sTbIrya7du3cv5EeQpGVtYiGS5PHAR4DXV9UD++o6oK320f7TjVUXVtWGqtqwevXq+RcrSRpoIiGS5CB6AfKBqvpoa/52O0xF+3lva58GjuhbfS1w9z7aJUljMomrswJcBNxSVe/oW7QDmLnCagtwVV/7K9pVWscD97fDXdcAJyc5tJ1QP7m1SZLGZOUEtnkC8HLgxiQ3tLY3A28DrkhyFnAn8JK27GrgNGAKeBB4FUBV7UnyVuBLrd9bqmrPKAvftvO2Ub49AG940dNHvg1JWihjD5Gq+l8MPp8BcNKA/gWcPcd7XQxcvHDVaSEZutLPPr+xLknqzBCRJHVmiEiSOjNEJEmdGSKSpM4MEUlSZ4aIJKkzQ0SS1JkhIknqzBCRJHVmiEiSOjNEJEmdGSKSpM4MEUlSZ4aIJKkzQ0SS1JkhIknqzBCRJHVmiEiSOjNEJEmdGSKSpM4MEUlSZ4aIJKkzQ0SS1JkhIknqzBCRJHW25EMkycYktyaZSnLOpOuRpOVkSYdIkhXAnwCnAscAL01yzGSrkqTlY0mHCHAcMFVVd1TVw8BlwKYJ1yRJy0aqatI1dJbkTGBjVb26zb8ceF5VvWZWv63A1jZ7NHBrx00eBnyn47qjZF3zY13zY13z87Na1y9U1erZjSsP4A0Xgwxo+6lUrKoLgQsPeGPJrqracKDvs9Csa36sa36sa36WW11L/XDWNHBE3/xa4O4J1SJJy85SD5EvAeuTHJXk0cBmYMeEa5KkZWNJH86qqr1JXgNcA6wALq6qm0e4yQM+JDYi1jU/1jU/1jU/y6quJX1iXZI0WUv9cJYkaYIMEUlSZ4bILEkuTnJvkpvmWJ4kF7TbrHw1ybGLpK4XJLk/yQ3t9QdjquuIJJ9LckuSm5O8bkCfsY/ZkHWNfcySHJzkuiT/u9X1Xwb0eUySy9t4XZtk3SKp65VJdveN16tHXVfftlck+UqSTwxYNvbxGrKuiYxXkm8mubFtc9eA5Qv7+1hVvvpewPOBY4Gb5lh+GvBJet9ROR64dpHU9QLgExMYr8OBY9v0E4DbgGMmPWZD1jX2MWtj8Pg2fRBwLXD8rD6/A7yvTW8GLl8kdb0SePe4/x9r234j8MFB/70mMV5D1jWR8QK+CRy2j+UL+vvonsgsVfUFYM8+umwCLqmeLwKrkhy+COqaiKq6p6q+3Ka/D9wCrJnVbexjNmRdY9fG4O/a7EHtNfvqlk3A9jZ9JXBSkkFfrB13XRORZC3w68CfzdFl7OM1ZF2L1YL+Phoi87cGuKtvfppF8I9T86vtcMQnkzxj3BtvhxGeQ++v2H4THbN91AUTGLN2COQG4F5gZ1XNOV5VtRe4H3jKIqgL4F+1QyBXJjliwPJReCfwe8CP51g+kfEaoi6YzHgV8NdJrk/vlk+zLejvoyEyf0PdamUCvkzv3jbPBv4H8PFxbjzJ44GPAK+vqgdmLx6wyljGbD91TWTMqupHVfVP6N1h4bgkz5zVZSLjNURdfwmsq6pnAZ/mH/76H5kkLwburarr99VtQNtIx2vIusY+Xs0JVXUsvbubn53k+bOWL+h4GSLztyhvtVJVD8wcjqiqq4GDkhw2jm0nOYjeP9QfqKqPDugykTHbX12THLO2ze8Bnwc2zlr0k/FKshJ4EmM8lDlXXVX13ap6qM2+H3juGMo5ATg9yTfp3aX7xCR/MavPJMZrv3VNaLyoqrvbz3uBj9G723m/Bf19NETmbwfwinaFw/HA/VV1z6SLSvJzM8eBkxxH77/td8ew3QAXAbdU1Tvm6Db2MRumrkmMWZLVSVa16UOAFwJfn9VtB7ClTZ8JfLbaGdFJ1jXruPnp9M4zjVRVnVtVa6tqHb2T5p+tqn83q9vYx2uYuiYxXkkel+QJM9PAycDsKzoX9PdxSd/2ZBSSfIjeVTuHJZkGzqN3kpGqeh9wNb2rG6aAB4FXLZK6zgR+O8le4AfA5lH/IjUnAC8HbmzH0wHeDBzZV9skxmyYuiYxZocD29N7oNqjgCuq6hNJ3gLsqqod9MLv0iRT9P6i3jzimoat67VJTgf2trpeOYa6BloE4zVMXZMYr6cBH2t/G60EPlhVn0ryH2E0v4/e9kSS1JmHsyRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR19v8BT38l6eA5M1YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['review_rating'].plot.hist(bins=12, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    11878\n",
       "4     6622\n",
       "3     3074\n",
       "1     1741\n",
       "2     1735\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()\n",
    "# df['target'] = df['review_rating'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['target'] = df['review_rating'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25050 entries, 0 to 25049\n",
      "Data columns (total 5 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   review_rating          25050 non-null  object\n",
      " 1   Reviews_tokenize_join  25050 non-null  object\n",
      " 2   target                 25050 non-null  object\n",
      " 3   new                    0 non-null      object\n",
      " 4   binamial_target        25050 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 978.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_rating</th>\n",
       "      <th>Reviews_tokenize_join</th>\n",
       "      <th>target</th>\n",
       "      <th>new</th>\n",
       "      <th>binamial_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>start say understand hard time city country en...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>wonderful visit time park view thank upgrade l...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>good hotel stay absolutely worth money view ce...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>fantastic location spot step central park view...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>amazing park view nicole staff professional fr...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_rating                              Reviews_tokenize_join target  \\\n",
       "0             1  start say understand hard time city country en...    Bad   \n",
       "1             5  wonderful visit time park view thank upgrade l...    Bad   \n",
       "2             5  good hotel stay absolutely worth money view ce...    Bad   \n",
       "3             5  fantastic location spot step central park view...    Bad   \n",
       "4             5  amazing park view nicole staff professional fr...    Bad   \n",
       "\n",
       "   new binamial_target  \n",
       "0  NaN             Bad  \n",
       "1  NaN            Good  \n",
       "2  NaN            Good  \n",
       "3  NaN            Good  \n",
       "4  NaN            Good  "
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classifier(LinearSVC())\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf(model ,col1,col):\n",
    "    start = timeit.timeit()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[col1], df[col] , test_size=0.3, random_state = 42)\n",
    "\n",
    "    classification_model = Pipeline([('vect', TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\", sublinear_tf=True)),\n",
    "                         ('chi',  SelectKBest(chi2, k=10000)),\n",
    "                   ('clf', model)])\n",
    "\n",
    "    classification_model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    preds = classification_model.predict(X_test)\n",
    "    end = timeit.timeit()\n",
    "    final_time = start - end\n",
    "\n",
    "    list_names = ['Model','Accuracy_score','Recall_score','Precision_score','F1_score', 'Time']\n",
    "    score_list = []\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds,average=None, pos_label='Good')\n",
    "    precision = precision_score(y_test, preds,average=None, pos_label='Good')\n",
    "    f_1 = f1_score(y_test , preds,average=None, pos_label='Good')\n",
    "#     roc_auc = metrics.roc_auc_score(y_test, preds)\n",
    "    final_time = start - end\n",
    "\n",
    "    score_list.extend([model,accuracy,recall,precision,f_1,final_time])\n",
    "    dictionary = dict(zip(list_names, score_list))\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clf(model):\n",
    "#     start = timeit.timeit()\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(df['Reviews_tokenize_join'] ,df['target'], test_size=0.3, random_state = 42)\n",
    "\n",
    "#     classification_model = Pipeline([('vect', TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\", sublinear_tf=True)),\n",
    "#                          ('chi',  SelectKBest(chi2, k=10000)),\n",
    "#                    ('clf', model)])\n",
    "\n",
    "# #     dt_cv_score = cross_val_score(nb, X_train, y_train, cv=3)\n",
    "# #     mean_dt_cv_score = np.mean(dt_cv_score)\n",
    "\n",
    "# #     print(f\"Mean Cross Validation Score: {mean_dt_cv_score :.2%}\")\n",
    "#     classification_model.fit(X_train, y_train)\n",
    "\n",
    "#     y_pred = classification_model.predict(X_test)\n",
    "#     end = timeit.timeit()\n",
    "#     print(f'Classier:{model} , Time: {start - end}')\n",
    "#     print(f'Accuracy: {accuracy_score(y_pred, y_test)}')\n",
    "#     print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'Accuracy_score': 0.5961410512308716,\n",
       " 'Recall_score': array([0.54420432, 0.03214286, 0.24946004, 0.39164619, 0.90588235]),\n",
       " 'Precision_score': array([0.57708333, 0.3       , 0.37806874, 0.47412255, 0.67414051]),\n",
       " 'F1_score': array([0.56016178, 0.05806452, 0.30058556, 0.42895587, 0.77301665]),\n",
       " 'Time': 0.0018814630000179022}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_multi_class = clf(LogisticRegression() , 'Reviews_tokenize_join', 'target')\n",
    "lg_multi_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_multi_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) , Time: 0.0022849209990454256\n",
      "Accuracy: 0.474251497005988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.01      0.02       509\n",
      "           2       0.00      0.00      0.00       560\n",
      "           3       0.09      0.01      0.01       926\n",
      "           4       0.12      0.04      0.06      2035\n",
      "           5       0.51      1.00      0.67      3485\n",
      "\n",
      "    accuracy                           0.47      7515\n",
      "   macro avg       0.34      0.21      0.15      7515\n",
      "weighted avg       0.35      0.47      0.33      7515\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "nb_multi_class = clf(MultinomialNB(),'Reviews_tokenize_join', 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_multi_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best') , Time: 0.004389895000713295\n",
      "Accuracy: 0.4637391882900865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.32      0.34       509\n",
      "           2       0.21      0.15      0.18       560\n",
      "           3       0.24      0.23      0.23       926\n",
      "           4       0.35      0.36      0.36      2035\n",
      "           5       0.62      0.66      0.64      3485\n",
      "\n",
      "    accuracy                           0.46      7515\n",
      "   macro avg       0.36      0.34      0.35      7515\n",
      "weighted avg       0.45      0.46      0.46      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_mult_class = (DecisionTreeClassifier(), 'Reviews_tokenize_join', 'target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine with stochastic gradient descent (SGD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False) , Time: 0.0028529249993880512\n",
      "Accuracy: 0.589620758483034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.75      0.57       509\n",
      "           2       0.33      0.10      0.16       560\n",
      "           3       0.46      0.26      0.33       926\n",
      "           4       0.50      0.19      0.28      2035\n",
      "           5       0.64      0.97      0.77      3485\n",
      "\n",
      "    accuracy                           0.59      7515\n",
      "   macro avg       0.48      0.45      0.42      7515\n",
      "weighted avg       0.55      0.59      0.52      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clf(SGDClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score: 53.50%\n",
      "Classier:SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=42, shuffle=True, tol=None, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False) , Time: 0.0021226449998721364\n",
      "Accuracy: 0.5141716566866268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.45      0.46       509\n",
      "           2       0.36      0.08      0.13       560\n",
      "           3       0.34      0.06      0.11       926\n",
      "           4       0.38      0.03      0.06      2035\n",
      "           5       0.53      1.00      0.69      3485\n",
      "\n",
      "    accuracy                           0.51      7515\n",
      "   macro avg       0.42      0.32      0.29      7515\n",
      "weighted avg       0.45      0.51      0.39      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with cross validation\n",
    "# clf(SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=42, shuffle=True, tol=None, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False) , Time: 0.00526697400005105\n",
      "Accuracy: 0.5141716566866268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.45      0.46       509\n",
      "           2       0.36      0.08      0.13       560\n",
      "           3       0.34      0.06      0.11       926\n",
      "           4       0.38      0.03      0.06      2035\n",
      "           5       0.53      1.00      0.69      3485\n",
      "\n",
      "    accuracy                           0.51      7515\n",
      "   macro avg       0.42      0.32      0.29      7515\n",
      "weighted avg       0.45      0.51      0.39      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clf(SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) , Time: 0.0006291960016824305\n",
      "Accuracy: 0.6087824351297405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.59      0.56       509\n",
      "           2       0.35      0.14      0.20       560\n",
      "           3       0.40      0.36      0.38       926\n",
      "           4       0.50      0.41      0.45      2035\n",
      "           5       0.72      0.87      0.79      3485\n",
      "\n",
      "    accuracy                           0.61      7515\n",
      "   macro avg       0.50      0.47      0.48      7515\n",
      "weighted avg       0.58      0.61      0.59      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_multi_class = clf(LinearSVC(),'Reviews_tokenize_join', 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=3000,\n",
      "          multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,\n",
      "          verbose=0) , Time: 0.001874255000075209\n",
      "Accuracy: 0.6059880239520958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.64      0.57       509\n",
      "           2       0.33      0.16      0.21       560\n",
      "           3       0.39      0.31      0.34       926\n",
      "           4       0.50      0.40      0.45      2035\n",
      "           5       0.72      0.87      0.79      3485\n",
      "\n",
      "    accuracy                           0.61      7515\n",
      "   macro avg       0.49      0.48      0.47      7515\n",
      "weighted avg       0.57      0.61      0.58      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clf(LinearSVC(C=1.0, penalty='l1', max_iter=3000, dual=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.ensemble import RandomForestClassifier\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False) , Time: -0.0008938350001699291\n",
      "Accuracy: 0.5123087159015303\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.33      0.39       509\n",
      "           2       0.33      0.08      0.12       560\n",
      "           3       0.31      0.18      0.23       926\n",
      "           4       0.35      0.33      0.34      2035\n",
      "           5       0.61      0.80      0.69      3485\n",
      "\n",
      "    accuracy                           0.51      7515\n",
      "   macro avg       0.42      0.34      0.36      7515\n",
      "weighted avg       0.47      0.51      0.48      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_multi_class = clf(RandomForestClassifier(),'Reviews_tokenize_join', 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clf_gs(model):\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(df['Reviews_tokenize_join'] ,df['target'], test_size=0.3, random_state = 42)\n",
    "\n",
    "#     nb = Pipeline([('vect', TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\", sublinear_tf=True)),\n",
    "#                          ('chi',  SelectKBest(chi2, k=10000)),\n",
    "#                    ('clf', model)])\n",
    "#     parameters = {'clf__penalty':['l1', 'l2'], 'clf__C':[0.001,0.1,10,100,10e5] , 'clf__gamma':[0.1,0.01]}\n",
    "#     # Instantiate GridSearchCV\n",
    "#     dt_grid_search = GridSearchCV(nb, parameters, cv=3, return_train_score=True)\n",
    "    \n",
    "#     dt_grid_search.fit(X_train, y_train)\n",
    "#     # Mean training score\n",
    "#     dt_gs_training_score = np.mean(dt_grid_search.cv_results_['mean_train_score'])\n",
    "\n",
    "#     # Mean test score\n",
    "#     dt_gs_testing_score = dt_grid_search.score(X_test, y_test)\n",
    "\n",
    "#     print(f\"Mean Training Score: {dt_gs_training_score :.2%}\")\n",
    "#     print(f\"Mean Test Score: {dt_gs_testing_score :.2%}\")\n",
    "#     print(\"Best Parameter Combination Found During Grid Search:\")\n",
    "#     dt_grid_search.best_params_\n",
    "\n",
    "\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clf_grid(model , parameteres):   \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(df['Reviews_tokenize_join'] ,df['target'], test_size=0.3, random_state = 42)\n",
    "\n",
    "#     pipeline = Pipeline([('vect', TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\", sublinear_tf=True)),\n",
    "#                          ('chi',  SelectKBest(chi2, k=10000)),\n",
    "#                          ('clf', model)])\n",
    "#     grid = GridSearchCV(pipeline, param_grid=parameteres, cv=5)\n",
    "#     grid.fit(X_train, y_train)\n",
    "#     print(f'accuracy:{grid.score(X_test,y_test)}')\n",
    "#     print(f'Best parameters : {grid.best_params_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_grid(model ,col,col1, parameteres):  \n",
    "    start = timeit.timeit()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['Reviews_tokenize_join'] ,df['target'], test_size=0.3, random_state = 42)\n",
    "\n",
    "    pipeline = Pipeline([('vect', TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\", sublinear_tf=True)),\n",
    "                         ('chi',  SelectKBest(chi2, k=10000)),\n",
    "                         ('clf', model)])\n",
    "    grid = GridSearchCV(pipeline, param_grid=parameteres, cv=5)\n",
    "    grid.fit(X_train, y_train)\n",
    "    m_best = grid.best_estimator_\n",
    "    y_pred = m_best.predict(X_test)\n",
    "\n",
    "\n",
    "    end = timeit.timeit()\n",
    "    final_time = start - end\n",
    "\n",
    "    list_names = ['Model','Accuracy_score','Recall_score','Precision_score','F1_score', 'Time']\n",
    "    score_list = []\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred,average=None, pos_label='Good')\n",
    "    precision = precision_score(y_test, y_pred,average=None, pos_label='Good')\n",
    "    f_1 = f1_score(y_test , y_pred,average=None, pos_label='Good')\n",
    "#     roc_auc = metrics.roc_auc_score(y_test, preds)\n",
    "    final_time = start - end\n",
    "\n",
    "    score_list.extend([model,accuracy,recall,precision,f_1,final_time])\n",
    "    dictionary = dict(zip(list_names, score_list))\n",
    "    return dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion with GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_multi_grid = clf_grid(LogisticRegression(),'Reviews_tokenize_join', 'target',parameteres = {'clf__C':[0.01, 0.1, 1, 10, 100] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'Accuracy_score': 0.6127744510978044,\n",
       " 'Recall_score': array([0.5481336 , 0.15714286, 0.39416847, 0.42948403, 0.86054519]),\n",
       " 'Precision_score': array([0.5625    , 0.34509804, 0.42491269, 0.50432776, 0.71883988]),\n",
       " 'F1_score': array([0.55522388, 0.21595092, 0.40896359, 0.46390658, 0.78333551]),\n",
       " 'Time': 0.001937517999863303}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_multi_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.ensemble import RandomForestClassifier\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.5958749168330006\n",
      "Best parameters : {'clf__alpha': 0.5, 'clf__fit_prior': False}\n"
     ]
    }
   ],
   "source": [
    "nb_muti_grid = clf_grid(MultinomialNB(),'Reviews_tokenize_join', 'target', parameteres = {'clf__alpha': np.linspace(0.5, 1.5, 6), 'clf__fit_prior': [True, False]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_muti_grid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.5076513639387891\n",
      "Best parameters : {'clf__criterion': 'gini', 'clf__max_depth': 6, 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "dt_multi_grid = clf_grid(DecisionTreeClassifier(),'Reviews_tokenize_join', 'target',parameteres = {\n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "    'clf__max_depth': [None, 2, 3, 4, 5, 6],\n",
    "    'clf__min_samples_split': [2, 5, 10],\n",
    "    'clf__min_samples_leaf': [1, 2, 3, 4, 5, 6]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_multi_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_multi_grid = clf_grid(RandomForestClassifier(),'Reviews_tokenize_join', 'target', parameteres = {\n",
    "    'clf__n_estimators': [10, 30, 100],\n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "    'clf__max_depth': [None, 2, 6, 10],\n",
    "    'clf__min_samples_split': [5, 10],\n",
    "    'clf__min_samples_leaf': [3, 6]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_multi_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Linear Support Vector Classification with GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.5984031936127745\n",
      "Best parameters : {'clf__C': 0.1, 'clf__max_iter': 1000}\n"
     ]
    }
   ],
   "source": [
    "svc_multi_grid = clf_grid(LinearSVC(), 'Reviews_tokenize_join', 'target' ,parameteres = {'clf__C':[0.001,0.1,10,100,10e5], 'clf__max_iter':[1000, 2000,3000]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_multi_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change target to 3 categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tree_categories = df.replace({5: 'good', 4: 'neutral', 3: 'bad' , 2: 'bad', 1: 'bad'})\n",
    "# df_tree_categories.head()\n",
    "df['tri_target'] = 'Bad'\n",
    "df.loc[df['review_rating'] == 5, 'tri_target'] = 'Good'\n",
    "df.loc[df['review_rating'] == 4, 'tri_target'] = 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good       11878\n",
       "Neutral     6622\n",
       "Bad         6550\n",
       "Name: tri_target, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tri_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a191a9048>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_tree_categories['target'].plot.bar(bins=12, alpha=0.5)\n",
    "df['tri_target'].value_counts().sort_values().plot(kind = 'barh')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clf(model):\n",
    "#     start = timeit.timeit()\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(df_tree_categories['Reviews_tokenize_join'],df_tree_categories['target'] , test_size=0.3, random_state = 42)\n",
    "\n",
    "#     classification_model = Pipeline([('vect', TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\", sublinear_tf=True)),\n",
    "#                          ('chi',  SelectKBest(chi2, k=10000)),\n",
    "#                    ('clf', model)])\n",
    "\n",
    "# #     dt_cv_score = cross_val_score(nb, X_train, y_train, cv=3)\n",
    "# #     mean_dt_cv_score = np.mean(dt_cv_score)\n",
    "\n",
    "# #     print(f\"Mean Cross Validation Score: {mean_dt_cv_score :.2%}\")\n",
    "#     classification_model.fit(X_train, y_train)\n",
    "\n",
    "#     y_pred = classification_model.predict(X_test)\n",
    "#     end = timeit.timeit()\n",
    "#     print(f'Classier:{model} , Time: {start - end}')\n",
    "#     accuracy = round(accuracy_score(y_pred, y_test) * 100 ,2)\n",
    "#     print(f'Accuracy: {accuracy}')\n",
    "#     print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clf(df, col, model):\n",
    "#     try:\n",
    "#         start = timeit.timeit()\n",
    "\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(df[col],df[col] , test_size=0.3, random_state = 42)\n",
    "\n",
    "#         classification_model = Pipeline([('vect', TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\", sublinear_tf=True)),\n",
    "#                              ('chi',  SelectKBest(chi2, k=10000)),\n",
    "#                        ('clf', model)])\n",
    "\n",
    "#     #     dt_cv_score = cross_val_score(nb, X_train, y_train, cv=3)\n",
    "#     #     mean_dt_cv_score = np.mean(dt_cv_score)\n",
    "\n",
    "#     #     print(f\"Mean Cross Validation Score: {mean_dt_cv_score :.2%}\")\n",
    "#         classification_model.fit(X_train, y_train)\n",
    "\n",
    "#         y_pred = classification_model.predict(X_test)\n",
    "#         end = timeit.timeit()\n",
    "#         print(f'Classier:{model} , Time: {start - end}')\n",
    "#         accuracy = round(accuracy_score(y_pred, y_test) * 100 ,2)\n",
    "#         print(f'Accuracy: {accuracy}')\n",
    "#         print(classification_report(y_test, y_pred))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf(df_tree_categories['Reviews_tokenize_join'],df_tree_categories['target'] ,LogisticRegression())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regressiom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_tri_class =clf( LogisticRegression(), 'Reviews_tokenize_join', 'tri_target')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'Accuracy_score': 0.7161676646706587,\n",
       " 'Recall_score': array([0.81954887, 0.88579627, 0.32432432]),\n",
       " 'Precision_score': array([0.80225711, 0.71491431, 0.56945643]),\n",
       " 'F1_score': array([0.81081081, 0.79123414, 0.41327489]),\n",
       " 'Time': 0.002936557999873912}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld_tri_class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best') , Time: 0.004610341005900409\n",
      "Accuracy: 53.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.61      0.50      0.55      1995\n",
      "        good       0.61      0.66      0.64      3485\n",
      "     neutral       0.33      0.35      0.34      2035\n",
      "\n",
      "    accuracy                           0.53      7515\n",
      "   macro avg       0.52      0.50      0.51      7515\n",
      "weighted avg       0.54      0.53      0.53      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_tri_class = clf(DecisionTreeClassifier(), 'Reviews_tokenize_join', 'tri_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_tri_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) , Time: 0.0046771149936830625\n",
      "Accuracy: 65.38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.87      0.68      0.77      1995\n",
      "        good       0.60      0.98      0.75      3485\n",
      "     neutral       0.47      0.06      0.11      2035\n",
      "\n",
      "    accuracy                           0.65      7515\n",
      "   macro avg       0.65      0.58      0.54      7515\n",
      "weighted avg       0.64      0.65      0.58      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_tri_class = clf(MultinomialNB(), 'Reviews_tokenize_join', 'tri_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_tri_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine with stochastic gradient descent (SGD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False) , Time: 0.004174531000899151\n",
      "Accuracy: 70.39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.73      0.89      0.81      1995\n",
      "        good       0.69      0.94      0.80      3485\n",
      "     neutral       0.68      0.11      0.20      2035\n",
      "\n",
      "    accuracy                           0.70      7515\n",
      "   macro avg       0.70      0.65      0.60      7515\n",
      "weighted avg       0.70      0.70      0.64      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_tri_class= clf(SGDClassifier(), 'Reviews_tokenize_join', 'tri_target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) , Time: 0.003260140001657419\n",
      "Accuracy: 71.32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.79      0.83      0.81      1995\n",
      "        good       0.74      0.85      0.79      3485\n",
      "     neutral       0.53      0.36      0.43      2035\n",
      "\n",
      "    accuracy                           0.71      7515\n",
      "   macro avg       0.69      0.68      0.68      7515\n",
      "weighted avg       0.69      0.71      0.70      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_tri_class = clf(LinearSVC(), 'Reviews_tokenize_join', 'tri_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_tri_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False) , Time: 0.004170633001194801\n",
      "Accuracy: 62.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.74      0.62      0.67      1995\n",
      "        good       0.63      0.89      0.73      3485\n",
      "     neutral       0.43      0.19      0.26      2035\n",
      "\n",
      "    accuracy                           0.63      7515\n",
      "   macro avg       0.60      0.57      0.56      7515\n",
      "weighted avg       0.60      0.63      0.59      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_tri_class = clf(RandomForestClassifier(), 'Reviews_tokenize_join', 'tri_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tri_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tunning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clf_grid(df, model , parameteres):   \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(df['Reviews_tokenize_join'] ,df['target'], test_size=0.3, random_state = 42)\n",
    "\n",
    "#     pipeline = Pipeline([('vect', TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\", sublinear_tf=True)),\n",
    "#                          ('chi',  SelectKBest(chi2, k=10000)),\n",
    "#                          ('clf', model)])\n",
    "#     grid = GridSearchCV(pipeline, param_grid=parameteres, cv=5)\n",
    "#     grid.fit(X_train, y_train)\n",
    "#     print(f'accuracy:{grid.score(X_test,y_test)}')\n",
    "#     print(f'Best parameters : {grid.best_params_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loigistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.7161676646706587\n",
      "Best parameters : {'clf__C': 1, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "lg_tri_grid = clf_grid(LogisticRegression(),'Reviews_tokenize_join', 'tri_target', parameteres ={'clf__penalty' : ['l1', 'l2'],\n",
    "# 'clf__C' : [ 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "# 'clf__solver': ['liblinear', 'saga']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.7161676646706587\n",
      "Best parameters : {'clf__C': 1}\n"
     ]
    }
   ],
   "source": [
    "clf_grid(df_tree_categories, LogisticRegression(),'Reviews_tokenize_join', 'tri_target',parameters_lg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_tri_grid = clf_grid( DecisionTreeClassifier(),'Reviews_tokenize_join', 'tri_target', parameteres = {\n",
    "#     'clf__criterion': ['gini', 'entropy'],\n",
    "#     'clf__max_depth': [None, 2, 3, 4, 5, 6],\n",
    "#     'clf__min_samples_split': [2, 5, 10],\n",
    "#     'clf__min_samples_leaf': [1, 2, 3, 4, 5, 6]\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.ensemble import RandomForestClassifier\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.7153692614770459\n",
      "Best parameters : {'clf__alpha': 0.5, 'clf__fit_prior': False}\n"
     ]
    }
   ],
   "source": [
    "nb_tri_grid = clf_grid( MultinomialNB(),'Reviews_tokenize_join', 'tri_target', parameteres = {'clf__alpha': np.linspace(0.5, 1.5, 6), 'clf__fit_prior': [True, False]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.7166999334664005\n",
      "Best parameters : {'clf__C': 0.1, 'clf__max_iter': 1000}\n"
     ]
    }
   ],
   "source": [
    "svc_tri_grid = clf_grid( LinearSVC() , 'Reviews_tokenize_join', 'tri_target',parameteres = {'clf__C':[0.001,0.1,10,100,10e5], 'clf__max_iter':[1000, 2000,3000]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tri_grid = clf_grid( RandomForestClassifier(), 'Reviews_tokenize_join', 'tri_target', parameteres = {\n",
    "#     'clf__n_estimators': [10, 30, 100],\n",
    "#     'clf__criterion': ['gini', 'entropy'],\n",
    "#     'clf__max_depth': [None, 2, 6, 10],\n",
    "#     'clf__min_samples_split': [5, 10],\n",
    "#     'clf__min_samples_leaf': [3, 6]\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change target to 2 categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bi_target'] = 'Bad'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['review_rating'] == 5, 'bi_target'] = 'Good'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_rating</th>\n",
       "      <th>Reviews_tokenize_join</th>\n",
       "      <th>target</th>\n",
       "      <th>tri_target</th>\n",
       "      <th>binamial_target</th>\n",
       "      <th>bi_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>start say understand hard time city country en...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>wonderful visit time park view thank upgrade l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>good hotel stay absolutely worth money view ce...</td>\n",
       "      <td>5</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>fantastic location spot step central park view...</td>\n",
       "      <td>5</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>amazing park view nicole staff professional fr...</td>\n",
       "      <td>5</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_rating                              Reviews_tokenize_join target  \\\n",
       "0              1  start say understand hard time city country en...      1   \n",
       "1              5  wonderful visit time park view thank upgrade l...      5   \n",
       "2              5  good hotel stay absolutely worth money view ce...      5   \n",
       "3              5  fantastic location spot step central park view...      5   \n",
       "4              5  amazing park view nicole staff professional fr...      5   \n",
       "\n",
       "  tri_target binamial_target bi_target  \n",
       "0        Bad             Bad       Bad  \n",
       "1       Good            Good      Good  \n",
       "2       Good            Good      Good  \n",
       "3       Good            Good      Good  \n",
       "4       Good            Good      Good  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.binamial_target.value_counts(normalize = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1c0cd828>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['bi_target'].value_counts().sort_values().plot(kind = 'barh')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf(model):\n",
    "    start = timeit.timeit()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['Reviews_tokenize_join'],df['binamial_target'] , test_size=0.3, random_state = 42)\n",
    "\n",
    "    classification_model = Pipeline([('vect', TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\", sublinear_tf=True)),\n",
    "                         ('chi',  SelectKBest(chi2, k=10000)),\n",
    "                   ('clf', model)])\n",
    "\n",
    "    classification_model.fit(X_train, y_train)\n",
    "    y_pred = classification_model.predict(X_test)\n",
    "    \n",
    "    end = timeit.timeit()\n",
    "    final = start - end\n",
    "    \n",
    "    \n",
    "    accuracy = round(accuracy_score(y_pred, y_test) * 100 ,2)\n",
    "    precesion  = round(precision_score(y_pred, y_test) *100 , 2)\n",
    "    recal = recall_score(y_pred, y_test)\n",
    "    f1_score = f1_score(y_pred, y_test)\n",
    "\n",
    "    return ({\n",
    "        'Time': final,\n",
    "        'Accuracy_Score': test_accuracy,\n",
    "        'Precision_Score': precesion,\n",
    "        'Recal_Score' : recal,\n",
    "        'F1_Score': f1_score\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_metrics(labels, preds):\n",
    "#     print(\"Precision Score: {}\".format(precision_score(labels, preds)))\n",
    "#     print(\"Recall Score: {}\".format(recall_score(labels, preds)))\n",
    "#     print(\"Accuracy Score: {}\".format(accuracy_score(labels, preds)))\n",
    "#     print(\"F1 Score: {}\".format(f1_score(labels, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "pos_label=1 is not a valid label: array(['Bad', 'Good'], dtype='<U4')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-280-f1ddfc2d70a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-279-608180def429>\u001b[0m in \u001b[0;36mclf\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mprecesion\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mrecal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mf1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1567\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1569\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1570\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1415\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1244\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpresent_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m                     raise ValueError(\"pos_label=%r is not a valid label: \"\n\u001b[0;32m-> 1246\u001b[0;31m                                      \"%r\" % (pos_label, present_labels))\n\u001b[0m\u001b[1;32m   1247\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: pos_label=1 is not a valid label: array(['Bad', 'Good'], dtype='<U4')"
     ]
    }
   ],
   "source": [
    "lg_bi_class = clf( LogisticRegression(), 'Reviews_tokenize_join', 'bi_target')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_ll(model ,col1,col):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[col1], df[col] , test_size=0.3, random_state = 42)\n",
    "\n",
    "    classification_model = Pipeline([('vect', TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\", sublinear_tf=True)),\n",
    "                         ('chi',  SelectKBest(chi2, k=10000)),\n",
    "                   ('clf', model)])\n",
    "\n",
    "    classification_model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    preds = classification_model.predict(X_test)\n",
    "    list_names = ['Model','Accuracy_score','Recall_score','Precision_score','F1_score']\n",
    "    score_list = []\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds, pos_label='Good')\n",
    "    precision = precision_score(y_test, preds, pos_label='Good')\n",
    "    f_1 = f1_score(y_test , preds, pos_label='Good')\n",
    "#     roc_auc = metrics.roc_auc_score(y_test, preds)\n",
    "    score_list.extend([model,accuracy,recall,precision,f_1])\n",
    "    dictionary = dict(zip(list_names, score_list))\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_bi_class = clf(DecisionTreeClassifier(), 'Reviews_tokenize_join', 'bi_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) , Time: 0.003956167995056603\n",
      "Accuracy: 80.41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.83      0.80      0.81      4030\n",
      "        Good       0.78      0.81      0.79      3485\n",
      "\n",
      "    accuracy                           0.80      7515\n",
      "   macro avg       0.80      0.80      0.80      7515\n",
      "weighted avg       0.81      0.80      0.80      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_bi_class = clf(MultinomialNB(), 'Reviews_tokenize_join', 'bi_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False) , Time: 0.0029596269960165955\n",
      "Accuracy: 80.56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.84      0.79      0.81      4030\n",
      "        Good       0.77      0.82      0.80      3485\n",
      "\n",
      "    accuracy                           0.81      7515\n",
      "   macro avg       0.81      0.81      0.81      7515\n",
      "weighted avg       0.81      0.81      0.81      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf(SGDClassifier(), 'Reviews_tokenize_join', 'bi_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classier:LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) , Time: 0.003953686995373573\n",
      "Accuracy: 80.49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.83      0.79      0.81      4030\n",
      "        Good       0.77      0.82      0.80      3485\n",
      "\n",
      "    accuracy                           0.80      7515\n",
      "   macro avg       0.80      0.81      0.80      7515\n",
      "weighted avg       0.81      0.80      0.81      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf(LinearSVC(), 'Reviews_tokenize_join', 'bi_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Reviews_tokenize_join'] ,df['target'], test_size=0.3, random_state = 42)\n",
    "\n",
    "pipeline = Pipeline([('vect', TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\", sublinear_tf=True)),\n",
    "                     ('chi',  SelectKBest(chi2, k=10000)),\n",
    "                     ('clf', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameteres = {'clf__C':[0.001,0.1,10,100,10e5], 'clf__max_iter':[1000, 2000,3000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipeline, param_grid=parameteres, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words...\n",
       "                                                  dual=True, fit_intercept=True,\n",
       "                                                  intercept_scaling=1,\n",
       "                                                  loss='squared_hinge',\n",
       "                                                  max_iter=1000,\n",
       "                                                  multi_class='ovr',\n",
       "                                                  penalty='l2',\n",
       "                                                  random_state=None, tol=0.0001,\n",
       "                                                  verbose=0))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'clf__C': [0.001, 0.1, 10, 100, 1000000.0],\n",
       "                         'clf__max_iter': [1000, 2000, 3000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6217564870259481\n"
     ]
    }
   ],
   "source": [
    "print(grid.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 0.1, 'clf__max_iter': 1000}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score: 56.49%\n",
      "Classier:LinearSVC(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,\n",
      "          verbose=0) , Time: 0.0035134449990437133\n",
      "Accuracy: 0.5720558882235529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.49      0.50       509\n",
      "           2       0.33      0.03      0.05       560\n",
      "           3       0.35      0.12      0.17       926\n",
      "           4       0.42      0.35      0.38      2035\n",
      "           5       0.65      0.92      0.76      3485\n",
      "\n",
      "    accuracy                           0.57      7515\n",
      "   macro avg       0.45      0.38      0.37      7515\n",
      "weighted avg       0.52      0.57      0.51      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf(LinearSVC(C=0.1, penalty='l1', max_iter=1000, dual=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score: 59.54%\n",
      "Classier:LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) , Time: 0.004986515999917174\n",
      "Accuracy: 0.5984031936127745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.61      0.57       509\n",
      "           2       0.40      0.04      0.08       560\n",
      "           3       0.40      0.23      0.29       926\n",
      "           4       0.48      0.37      0.41      2035\n",
      "           5       0.67      0.92      0.77      3485\n",
      "\n",
      "    accuracy                           0.60      7515\n",
      "   macro avg       0.50      0.43      0.43      7515\n",
      "weighted avg       0.56      0.60      0.55      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf(LinearSVC(C=0.1, max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score: 60.98%\n",
      "Classier:LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) , Time: 0.006638550999923609\n",
      "Accuracy: 0.6087824351297405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.59      0.56       509\n",
      "           2       0.35      0.14      0.20       560\n",
      "           3       0.40      0.36      0.38       926\n",
      "           4       0.50      0.41      0.45      2035\n",
      "           5       0.72      0.87      0.79      3485\n",
      "\n",
      "    accuracy                           0.61      7515\n",
      "   macro avg       0.50      0.47      0.48      7515\n",
      "weighted avg       0.58      0.61      0.59      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf(LinearSVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.6171656686626746\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy score: \" + str(model.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = model.named_steps['vect']\n",
    "chi = model.named_steps['chi']\n",
    "clf = model.named_steps['classifier']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nfrom sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['aand price', 'able coffee', 'able comfortable', 'able complain',\n",
       "       'able cook', 'able manually', 'able rebook', 'able suitcase',\n",
       "       'able text', 'able toilet'], dtype='<U28')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_names = [feature_names[i] for i in chi.get_support(indices=True)]\n",
    "feature_names = np.asarray(feature_names)\n",
    "feature_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 keywords per class:\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nfrom sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: total cost horrible ruin uncleaned experience superb avoid cost stay away disgusting bed uncomfortable bad\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nfrom sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: work leak sink didn book site like hadn rudest shoddy wasn worth soil feel dirty maze\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nfrom sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: room rude average average experience worth lobby date staff tall building pro despite request problem need leave floor\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nfrom sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: attend opera lobby large good reasonable overall location downside reason didn simple clean excellent right general good drawback\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nfrom sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5: perfect love worth penny andrew grateful absolutely stay emanuel exceed impressed overall excellent\n"
     ]
    }
   ],
   "source": [
    "target_names = ['1', '2', '3', '4', '5']\n",
    "print(\"top 10 keywords per class:\")\n",
    "for i, label in enumerate(target_names):\n",
    "    top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "    print(\"%s: %s\" % (label, \" \".join(feature_names[top10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## limpiar la data quetar names como did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
